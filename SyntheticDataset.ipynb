{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная версия 5 августа 2020. Все пути захардкожены, в будущем нужно поменять.  \n",
    "Версия 12 августа 2020. Написана функция download_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import wget\n",
    "import pyunpack\n",
    "import fileinput\n",
    "import glob\n",
    "from itertools import chain\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from transformers.tokenization_bert import BasicTokenizer\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDatasetGenerator:\n",
    "    def __init__(self, all_data, output_file, generate_type = ['tsya','nn', 'techenie', 'neni_b'], data_dir='data/'):\n",
    "        self.data_dir = data_dir\n",
    "        self.dataset_path = os.path.join(data_dir, all_data)\n",
    "        #self.download_data(self.data_dir)\n",
    "        \n",
    "        self.input_num_sentences = None\n",
    "        self.output_num_sentences = None\n",
    "        self.words = []\n",
    "        if 'tsya' in generate_type:\n",
    "            self.tysya_existing_words = None\n",
    "            self.tsya_existing_words = None\n",
    "            self.words += ['tsya', 'tysya']\n",
    "        if 'nn' in generate_type:\n",
    "            self.n_nn_existing_words = None\n",
    "            self.words += ['n', 'nn']\n",
    "        if 'techenie' in generate_type:\n",
    "            self.techenie_existing_words = None\n",
    "            self.words += ['techenie', 'techenii']\n",
    "        if 'neni_b' in generate_type:\n",
    "            self.ne_ni_existing_words = None \n",
    "            self.words += ['ne', 'ni']\n",
    "        self.generate_type = generate_type\n",
    "        self.load_dics()\n",
    "        self.taglist = ['REPLACE_tsya', 'REPLACE_tysya', 'REPLACE_nn, REPLACE_n', 'REPLACE_techenie', 'REPLACE_techenii'\n",
    "                           'REPLACE_ne', 'REPLACE_ni']\n",
    "        self.KEEP = 'O'\n",
    "        self.to_file = output_file\n",
    "        self.data = None\n",
    "    \n",
    "    def load_dics(self):\n",
    "        print('Loading dictionaries...')\n",
    "        \n",
    "        if 'techenie' in self.generate_type:\n",
    "            self.techenie_existing_words = set(['течение', 'течении'])\n",
    "        if 'tsya' in self.generate_type:\n",
    "            with open('data/tsya_vocab.txt', 'r') as f:\n",
    "                pairs = f.read().splitlines()\n",
    "            self.tysya_existing_words = set([pair.split('\\t')[0] for pair in pairs])\n",
    "            self.tsya_existing_words = set([pair.split('\\t')[1] for pair in pairs])\n",
    "        if 'nn' in self.generate_type:\n",
    "            if not os.path.exists('data/all_n_nn_words_full_endings.txt'):\n",
    "                with open('data/n_words.txt', 'r') as f:\n",
    "                    n_words = f.read().splitlines()\n",
    "                n_data = pd.DataFrame(n_words, columns=['text'])\n",
    "                n_data['text'] = n_data['text'].str.replace('\"Словоформа\": \"', '').str.strip('\"').str.strip()\n",
    "                # remove words with capital letters\n",
    "                to_filter = n_data[n_data['text'].str.contains(r'[А-ЯЁ]+', regex=True)]\n",
    "                #  keep those with capital letters which have a hyphen after them\n",
    "                to_append = to_filter[to_filter['text'].str.contains(r'[А-ЯЁ]+-')]\n",
    "                n_data = n_data[~n_data['text'].str.contains(r'[А-ЯЁ]+', regex=True)]\n",
    "                n_data = n_data.append(to_append)\n",
    "                nn_pattern = re.compile(r'\\wнн([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b', re.IGNORECASE)\n",
    "                n_pattern = re.compile(r'[аоэеиыуёюя]н([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b', re.IGNORECASE)\n",
    "                nn = n_data[n_data['text'].str.contains(nn_pattern, regex=True)]\n",
    "                n = n_data[n_data['text'].str.contains(n_pattern, regex=True)]\n",
    "                self.n_nn_existing_words = set(nn['text']).union(set(n['text']))\n",
    "                # add word writings with 'е' instead of 'ё'\n",
    "                without_yo = set()\n",
    "                for word in self.n_nn_existing_words:\n",
    "                    if word.find('ё') != -1:\n",
    "                        without_yo.add(word.replace('ё', 'е'))\n",
    "                self.n_nn_existing_words.update(without_yo)\n",
    "                # write n_nn_words to disk for further using out of the file\n",
    "                with open('data/all_n_nn_words_full_endings.txt', 'w') as f:\n",
    "                    for line in self.n_nn_existing_words:\n",
    "                        f.write(line + '\\n')\n",
    "            else:\n",
    "                with open('data/all_n_nn_words_full_endings.txt', 'r') as f:\n",
    "                    self.n_nn_existing_words = set(f.read().splitlines())\n",
    "        if 'neni_b' in self.generate_type:        \n",
    "            if not os.path.exists('data/all_ne_ni_words.txt'):\n",
    "                with open('data/ne_ni_words.txt', 'r') as f:\n",
    "                    ne_ni_words = f.read().splitlines()\n",
    "                ne_ni_data = pd.DataFrame(ne_ni_words, columns=['text'])\n",
    "                ne_ni_data['text'] = ne_ni_data['text'].str.replace('\"Словоформа\": \"', '').str.strip('\"').str.strip()\n",
    "                to_filter = ne_ni_data[ne_ni_data['text'].str.contains(r'[А-ЯЁ]+', regex=True)]\n",
    "                to_append = to_filter[to_filter['text'].str.contains(r'[А-ЯЁ]+-')]\n",
    "                ne_ni_data = ne_ni_data[~ne_ni_data['text'].str.contains(r'[А-ЯЁ]+', regex=True)]\n",
    "                ne_ni_data = ne_ni_data.append(to_append)\n",
    "                ne_pattern = re.compile(r'\\b([А-ЯЁ]+-)?не\\w+(\\b|-)', re.IGNORECASE)\n",
    "                ni_pattern = re.compile(r'\\b([А-ЯЁ]+-)?ни\\w+(\\b|-)', re.IGNORECASE)\n",
    "                ne = ne_ni_data[ne_ni_data['text'].str.contains(ne_pattern, regex=True)]\n",
    "                ni = ne_ni_data[ne_ni_data['text'].str.contains(ni_pattern, regex=True)]\n",
    "                bool_signs = ne['text'].str.replace('не', 'ни').isin(ni['text'])\n",
    "                ne_ni_existing_words = set(ne[bool_signs]['text']).union(set(ne[bool_signs]['text'].str.replace('не', 'ни')))\n",
    "                without_yo = set()\n",
    "                for word in ne_ni_existing_words:\n",
    "                    if word.find('ё') != -1:\n",
    "                        without_yo.add(word.replace('ё', 'е'))\n",
    "                ne_ni_existing_words.update(without_yo)\n",
    "                with open('data/all_ne_ni_words.txt', 'w') as f:\n",
    "                    for line in ne_ni_existing_words:\n",
    "                        f.write(line + '\\n')\n",
    "            else:\n",
    "                with open('data/all_ne_ni_words.txt', 'r') as f:\n",
    "                    self.ne_ni_existing_words = set(f.read().splitlines())\n",
    "            \n",
    "            \n",
    "    def download_data(self, data_dir):\n",
    "        print('Downloading data...')\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.mkdir(data_dir)\n",
    "        dataset_name = 'Magazines'\n",
    "        if os.path.exists(self.dataset_path):\n",
    "            print('all_data.txt already exists')\n",
    "        else:\n",
    "            archive_path = os.path.join(data_dir, dataset_name + '.rar')\n",
    "            if not os.path.exists(archive_path):\n",
    "                archive_url = 'https://linghub.ru/static/Taiga/' + dataset_name +'.rar'\n",
    "                filename = wget.download(archive_url, out=archive_path)\n",
    "            unrared_path = os.path.join(data_dir, dataset_name)\n",
    "            if not os.path.exists(unrared_path):            \n",
    "                pyunpack.Archive(archive_path).extractall(data_dir)\n",
    "            file_list = sorted(glob.glob(os.path.join(unrared_path, 'texts/*.txt')))\n",
    "            with open(self.dataset_path, 'w') as file:\n",
    "                input_lines = fileinput.input(file_list)\n",
    "                file.writelines(input_lines)\n",
    "\n",
    "        n_words_path = os.path.join(data_dir, 'n_words.txt')\n",
    "        if not os.path.exists(n_words_path):\n",
    "            all_orpho_words_path = os.path.join(data_dir, 'db_word_16.06.2020.json')\n",
    "            if not os.path.exists(all_orpho_words_path):\n",
    "                raise FileNotFoundError('Please put db_word_16.06.2020.json in ' + os.path.abspath(data_dir))\n",
    "            with open(all_orpho_words_path, 'r') as f:\n",
    "                with open(n_words_path, 'w') as writefile:\n",
    "                    line = f.readline()\n",
    "                    while line:\n",
    "                        line = f.readline()\n",
    "                        if re.search('н', line) and re.search('Словоформа', line):\n",
    "                            writefile.write(line)\n",
    "        \n",
    "        tsya_vocab_path = os.path.join(data_dir, 'tsya_vocab.txt')\n",
    "        if not os.path.exists(tsya_vocab_path):\n",
    "            raise FileNotFoundError('Please put tsya_vocab.txt in ' + os.path.abspath(data_dir))\n",
    "            \n",
    "        ne_ni_words_path = os.path.join(data_dir, 'ne_ni_words.txt')\n",
    "        if not os.path.exists(ne_ni_words_path):\n",
    "            all_orpho_words_path = os.path.join(data_dir, 'db_word_16.06.2020.json')\n",
    "            if not os.path.exists(all_orpho_words_path):\n",
    "                raise FileNotFoundError('Please put db_word_16.06.2020.json in ' + os.path.abspath(data_dir))\n",
    "            with open(all_orpho_words_path, 'r') as f:\n",
    "                with open(ne_ni_words_path, 'w') as writefile:\n",
    "                    line = f.readline()\n",
    "                    while line:\n",
    "                        line = f.readline()\n",
    "                        if re.search(r'\\b([А-ЯЁ]+-)?не', line) and re.search('Словоформа', line):\n",
    "                            writefile.write(line)\n",
    "                        elif re.search(r'\\b(\\b[А-ЯЁ]+-)?ни', line) and re.search('Словоформа', line):\n",
    "                            writefile.write(line)\n",
    "        # news_dataset      \n",
    "#         archive_url = 'http://bit.ly/2pvhWZm'\n",
    "#         filename = wget.download(archive_url, os.path.join('./data', 'news' + '.zip'))\n",
    "#         pyunpack.Archive('./data/news.zip').extractall('./data')\n",
    "\n",
    "#         file_list_full = []\n",
    "#         for folder in ['Fontanka', 'Lenta', 'KP', 'Interfax']:\n",
    "#             file_list_year = []\n",
    "#             for year_folder in os.listdir('./news/' + folder + '/texts/'):\n",
    "#                 file_list = sorted(glob.glob(os.path.join('./news/'+folder + '/texts/' + year_folder + '/', '*.txt')))\n",
    "#                 file_list_year.append(file_list)\n",
    "#             file_list_full.append(file_list_year)\n",
    "\n",
    "#         with open('news_dataset.txt', 'w') as file:\n",
    "#             for file_list_year in file_list_full:\n",
    "#                 for file_list in file_list_year:\n",
    "#                     input_lines = fileinput.input(file_list)\n",
    "#                     file.writelines(input_lines)\n",
    "        \n",
    "    \n",
    "    def select_data(self):\n",
    "        print('Selecting lines larger than 10 symbols...')\n",
    "        with open(self.dataset_path, 'r') as f:\n",
    "            texts = f.read().splitlines() # 6697245 lines\n",
    "            texts = [' '.join(line.split()) for line in texts if len(line) > 10] # 5014971 lines [5304067 lines]\n",
    "        return texts\n",
    "    \n",
    "    def sentence_tokenize(self, texts):\n",
    "        print('Splitting in sentences...')\n",
    "        sentences = list(chain.from_iterable(list(map(sent_tokenize, texts))))\n",
    "        self.input_num_sentences = len(sentences)\n",
    "        print('Input sentences before splitting on ... :', self.input_num_sentences)\n",
    "        new_sentences = []\n",
    "        for s in sentences:\n",
    "            longer = False\n",
    "            sen = re.split(r'\\.\\.\\.\\s|…\\s', s)\n",
    "            if len(sen) > 1:\n",
    "                longer = True\n",
    "            for i in range(len(sen)):\n",
    "                if longer and i < len(sen) - 1 and len(sen[i]) > 1:\n",
    "                    new_sentences.append(sen[i] + '...')\n",
    "                elif i == len(sen) - 1 and len(sen[i]) > 1:\n",
    "                    new_sentences.append(sen[i])\n",
    "        self.input_num_sentences = len(new_sentences)\n",
    "        print('Input sentences:', self.input_num_sentences)\n",
    "        return pd.DataFrame(new_sentences, columns=['text'])\n",
    "    \n",
    "    def filter_characters(self, data):\n",
    "        print('Filtering characters...')\n",
    "        # Heuristic for correct bert tokenization\n",
    "        data['text'] = data['text'].str.replace(r'[“”«»‘‛’„»«└″′]', \"'\", regex=True)\n",
    "        symbols_to_filter = set()\n",
    "        for i, sent in tqdm(enumerate(data['text'])):\n",
    "            for letter in sent:\n",
    "                if ord(letter) > ord('─'):\n",
    "                    symbols_to_filter.add(letter)\n",
    "        symbols_to_filter.update({'\\u200b','\\u200e', '´', '`'})\n",
    "        symbols_to_filter = ''.join(sym for sym in symbols_to_filter)\n",
    "        filter_regex = re.compile(r'[' + re.escape(symbols_to_filter) + r']')\n",
    "        data['text'] = data['text'].str.replace(filter_regex, '', regex=True)\n",
    "        return data\n",
    "    \n",
    "    def add_schitannye(self, data):\n",
    "        print(\"Add schitannye\")\n",
    "        schitan = re.compile(r'\\bсчитан[ые|ыми|ое]', flags=re.IGNORECASE)\n",
    "        schitann = re.compile(r'\\bсчитанн[ые|ыми|ое]', flags=re.IGNORECASE)\n",
    "        data['n_case'] = data['text'].str.contains(schitan, regex=True)\n",
    "        data['schitanye'] = data[data['n_case'].fillna(False)]['text']\n",
    "        data['nn_case']  = data['text'].str.contains(schitann, regex=True)\n",
    "        data['schitannye'] = data[data['nn_case'].fillna(False)]['text']\n",
    "        sizes = data.count().to_numpy()\n",
    "        k = sizes[4]-sizes[2]\n",
    "        print(k)\n",
    "        schitan_data = data['schitanye'].dropna().to_numpy()\n",
    "        base = k//sizes[2]*sizes[2]\n",
    "        df = pd.concat([pd.DataFrame([schitan_data[i]], columns=['text']) for i in range(sizes[2])], ignore_index=True)\n",
    "        df1 = pd.concat([data, df], ignore_index=True)\n",
    "        for r in range(k//sizes[2]-1):\n",
    "            df1 = pd.concat([df1, df], ignore_index=True)\n",
    "        df2 = pd.concat([pd.DataFrame([schitan_data[i]], columns=['text']) for i in range(k-base)], ignore_index=True)\n",
    "        data = pd.concat([df1, df2], ignore_index=True)     \n",
    "        return data.drop(columns=['schitanye', 'schitannye', 'n_case', 'nn_case'])\n",
    "    \n",
    "    def insert_correct_schitanye(self, data):\n",
    "        \n",
    "        print(\"Insert correct sentences with считаные/считанные\")\n",
    "        schitan = re.compile(r'\\bсчитан(?=[ые|ыми|ое])', flags=re.IGNORECASE)\n",
    "        schitann = re.compile(r'\\bсчитанн(?=[ые|ыми|ое])', flags=re.IGNORECASE)\n",
    "        data['n_case'] = data['text'].str.contains(schitan, regex=True)\n",
    "        data['nn_case'] = data['text'].str.contains(schitann, regex=True)\n",
    "        data['schitanye'] = data[data['n_case'].fillna(False)]['text']\n",
    "        data['schitannye'] = data[data['nn_case'].fillna(False)]['text']\n",
    "        df = pd.concat([data['schitanye'].dropna(), data['schitannye'].dropna()]) \n",
    "        with open('schitanyj_1n.txt', 'r') as f:\n",
    "            arr_n = f.readlines()\n",
    "        arr_n = [line.strip() for line in arr_n]\n",
    "        with open('schitannyj_2n.txt', 'r') as f:\n",
    "            arr_nn = f.readlines()\n",
    "        arr_nn = [line.strip() for line in arr_nn]\n",
    "        for i,sentence in tqdm(df.iteritems()):\n",
    "            if sentence in arr_n:\n",
    "                #if schitann.search(data.loc[df.index[i], 'text']) is not None:\n",
    "                if schitann.search(data.loc[i, 'text']) is not None:\n",
    "                    word = schitann.search(data.loc[i, 'text']).group()\n",
    "                    data.loc[i, 'text'] = data.loc[i, 'text'].replace(word, 'считан')\n",
    "            if sentence in arr_nn:\n",
    "                if schitan.search(data.loc[i, 'text']) is not None:\n",
    "                    word = schitan.search(data.loc[i, 'text']).group()\n",
    "                    data.loc[i, 'text'] = data.loc[i, 'text'].replace(word, 'считанн')\n",
    "        data = data.drop(columns=['schitanye', 'schitannye', 'n_case', 'nn_case'])\n",
    "        print(\"Data contains sentence, that is correct for both n and nn\", data[data.text == \"Они не могут быть считанными.\"]['text'])\n",
    "        if \"Они не могут быть считанными.\" in df.to_numpy():\n",
    "            print(\"contains\")\n",
    "            data.loc[len(data), \"text\"] = \"Они не могут быть считаными.\"\n",
    "        for dset in [df, arr_n, arr_nn]:\n",
    "            del dset\n",
    "        return data\n",
    "    \n",
    "    def mark_containing_tsya_tysya(self, data):\n",
    "        print('Marking tsya/tysya sentences...')\n",
    "        data['tsya'] = data['text'].str.contains(r'\\wтся', regex=True, flags=re.IGNORECASE)\n",
    "        data['tysya'] = data['text'].str.contains(r'\\wться', regex=True, flags=re.IGNORECASE)\n",
    "        full_tsya_pattern = r'\\b\\w*тся'\n",
    "        full_tysya_pattern = r'\\b\\w*ться'\n",
    "        data['all_tsya_words'] = data[data['tsya'].fillna(False)]['text'].str.findall(full_tsya_pattern, flags=re.IGNORECASE)\n",
    "        data['all_tysya_words'] = data[data['tysya'].fillna(False)]['text'].str.findall(full_tysya_pattern, flags=re.IGNORECASE)\n",
    "        print(len(data[data['tsya'].fillna(False)]), len(data[data['tysya'].fillna(False)]))\n",
    "        return data.drop(['tsya', 'tysya'], axis=1)\n",
    "\n",
    "    def mark_containing_n_nn(self, data):\n",
    "        print('Marking n/nn sentences...')\n",
    "        nn_pattern = re.compile(r'\\wнн([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b', re.IGNORECASE)\n",
    "        n_pattern = re.compile(r'[аоэеиыуёюя]н([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b', re.IGNORECASE)\n",
    "        data['nn'] = data['text'].str.contains(nn_pattern, regex=True)\n",
    "        data['n'] = data['text'].str.contains(n_pattern, regex=True)\n",
    "        full_n_pattern = r'\\b\\w*[аоэеиыуёюя]н(?:[аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b'\n",
    "        data['all_n_words'] = data[data['n'].fillna(False)]['text'].str.findall(full_n_pattern, flags=re.IGNORECASE)\n",
    "        full_nn_pattern = r'\\b\\w*нн(?:[аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b'\n",
    "        data['all_nn_words'] = data[data['nn'].fillna(False)]['text'].str.findall(full_nn_pattern, flags=re.IGNORECASE)\n",
    "        print(len(data[data['n'].fillna(False)]), len(data[data['nn'].fillna(False)]))\n",
    "        return data.drop(['n', 'nn'], axis=1)\n",
    "        \n",
    "    \n",
    "    def mark_containing_techenie_ii(self, data):\n",
    "        print('Marking techenie/techenii sentences...')\n",
    "        techenie_pattern = re.compile(r'\\bтечение\\b', re.IGNORECASE)\n",
    "        techenii_pattern = re.compile(r'\\bтечении\\b', re.IGNORECASE)\n",
    "        data['techenie'] = data['text'].str.contains(techenie_pattern, regex=True)\n",
    "        data['techenii'] = data['text'].str.contains(techenii_pattern, regex=True)\n",
    "\n",
    "        data['all_techenie_words'] = data[data['techenie'].fillna(False)]['text'].str.findall(r'\\bтечение\\b', flags=re.IGNORECASE)\n",
    "        data['all_techenii_words'] = data[data['techenii'].fillna(False)]['text'].str.findall(r'\\bтечении\\b', flags=re.IGNORECASE)\n",
    "        print(len(data[data['techenie'].fillna(False)]), len(data[data['techenii'].fillna(False)]))\n",
    "        return data.drop(['techenie', 'techenii'], axis=1)\n",
    "    \n",
    "    def mark_containing_ne_ni(self, data):\n",
    "        print('Marking ne/ni sentences...')\n",
    "        nе_pattern = re.compile(r'\\bне\\w+\\b', re.IGNORECASE)\n",
    "        ni_pattern = re.compile(r'\\bни\\w+\\b', re.IGNORECASE)\n",
    "        data['ne'] = data['text'].str.contains(nе_pattern, regex=True)\n",
    "        data['ni'] = data['text'].str.contains(ni_pattern, regex=True)\n",
    "\n",
    "        data['all_ne_words'] = data[data['ne'].fillna(False)]['text'].str.findall(nе_pattern, flags=re.IGNORECASE)\n",
    "        data['all_ni_words'] = data[data['ni'].fillna(False)]['text'].str.findall(ni_pattern, flags=re.IGNORECASE)\n",
    "        print(len(data[data['ne'].fillna(False)]), len(data[data['ni'].fillna(False)]))\n",
    "        return data.drop(['ne', 'ni'], axis=1)\n",
    "    \n",
    "    def generate_one_error_type(self, data, error_name):\n",
    "        print('Generating error', error_name, '...')\n",
    "        if error_name == 'tsya':\n",
    "            pattern_cased = re.compile(r'ТСЯ')\n",
    "            pattern = re.compile(r'тся', re.IGNORECASE)\n",
    "            substitute_cased = 'ТЬСЯ'\n",
    "            substitute = 'ться'\n",
    "            existing_words = self.tysya_existing_words\n",
    "        elif error_name == 'tysya':\n",
    "            pattern_cased = re.compile(r'ТЬСЯ')\n",
    "            pattern = re.compile(r'ться', re.IGNORECASE)\n",
    "            substitute_cased = 'ТСЯ'\n",
    "            substitute = 'тся'\n",
    "            existing_words = self.tsya_existing_words\n",
    "        elif error_name == 'n':\n",
    "            pattern_cased = re.compile(r'(?<=[аоэеиыуёюя])(?-i:Н)(?=([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b)', re.IGNORECASE)\n",
    "            pattern = re.compile(r'(?<=[аоэеиыуёюя])(?-i:н)(?=([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b)', re.IGNORECASE)\n",
    "            substitute_cased = 'НН'\n",
    "            substitute = 'нн'\n",
    "            existing_words = self.n_nn_existing_words\n",
    "        elif error_name == 'nn':\n",
    "            pattern_cased = re.compile(r'(?-i:НН)(?=([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b)', re.IGNORECASE)\n",
    "            pattern = re.compile(r'(?-i:нн)(?=([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b)', re.IGNORECASE)\n",
    "            substitute_cased = 'Н'\n",
    "            substitute = 'н'\n",
    "            existing_words = self.n_nn_existing_words\n",
    "        elif error_name == 'techenie':\n",
    "            pattern_cased = re.compile(r'\\bТЕЧЕНИЕ\\b', re.IGNORECASE)\n",
    "            pattern = re.compile(r'\\bтечение\\b', re.IGNORECASE)\n",
    "            substitute_cased = 'ТЕЧЕНИИ'\n",
    "            substitute = 'течении'\n",
    "            existing_words = self.techenie_existing_words\n",
    "        elif error_name == 'techenii':\n",
    "            pattern_cased = re.compile(r'\\bТЕЧЕНИИ\\b', re.IGNORECASE)\n",
    "            pattern = re.compile(r'\\bтечении\\b', re.IGNORECASE)\n",
    "            substitute_cased = 'ТЕЧЕНИЕ'\n",
    "            substitute = 'течение'\n",
    "            existing_words = self.techenie_existing_words\n",
    "        elif error_name == 'ne':\n",
    "            pattern_cased = re.compile(r'\\bНЕ\\w+\\b', re.IGNORECASE)\n",
    "            pattern = re.compile(r'\\bне\\w+\\b', re.IGNORECASE)\n",
    "            substitute_cased = 'НИ'\n",
    "            substitute = 'ни'\n",
    "            existing_words = self.ni_existing_words\n",
    "        elif error_name == 'ni':\n",
    "            pattern_cased = re.compile(r'\\bНИ\\w+\\b', re.IGNORECASE)\n",
    "            pattern = re.compile(r'\\bни\\w+\\b', re.IGNORECASE)\n",
    "            substitute_cased = 'НЕ'\n",
    "            substitute = 'не'\n",
    "            existing_words = self.ne_existing_words\n",
    "        original_array = []\n",
    "        changed_array = []\n",
    "        col_name = 'all_' + str(error_name) + '_words'\n",
    "        for line in data[col_name]:\n",
    "            if line is np.nan:\n",
    "                changed_array.append(np.nan)\n",
    "                original_array.append(np.nan)\n",
    "            else:\n",
    "                changed_line = []\n",
    "                original_line = []\n",
    "                for word in line:\n",
    "                    # the order is important! first cased pattern, then pattern\n",
    "                    changed_word = pattern_cased.sub(substitute_cased, word)\n",
    "                    changed_word = pattern.sub(substitute, changed_word)\n",
    "                    if changed_word.lower() in existing_words and changed_word != word:                        \n",
    "                        changed_line.append(changed_word)\n",
    "                        original_line.append(word)\n",
    "                if len(changed_line) == 0:\n",
    "                    changed_array.append(np.nan)\n",
    "                    original_array.append(np.nan)\n",
    "                else:\n",
    "                    changed_array.append(changed_line)\n",
    "                    original_array.append(original_line)\n",
    "        data[str(error_name) + '_words'] = original_array\n",
    "        data[str(error_name) + '_words_errorified'] = changed_array\n",
    "        return data.drop('all_' + str(error_name) + '_words', axis=1)\n",
    "\n",
    "    def filter_data_by_error_set(self, data):\n",
    "        \n",
    "        print('Filtering out the sentences that cannot be errorified...')\n",
    "        potential_cols = []\n",
    "        if 'tsya' in self.generate_type:\n",
    "            potential_cols = potential_cols + ['tsya_words_errorified','tysya_words_errorified']\n",
    "        if 'nn' in self.generate_type:\n",
    "            potential_cols = potential_cols + ['n_words_errorified', 'nn_words_errorified']\n",
    "        if 'techenie' in self.generate_type:\n",
    "            potential_cols = potential_cols + ['techenie_words_errorified', 'techenii_words_errorified']\n",
    "        if 'neni_b' in self.generate_type:\n",
    "            potential_cols = potential_cols + ['ne_words_errorified', 'ni_words_errorified']\n",
    "\n",
    "        #potential_cols = ['tsya_words_errorified', 'tysya_words_errorified', 'n_words_errorified', 'nn_words_errorified']\n",
    "        data.dropna(subset=potential_cols, how='all', inplace=True)\n",
    "        self.output_num_sentences = len(data)\n",
    "        print('Output sentences:', self.output_num_sentences)   \n",
    "        \n",
    "        return data, potential_cols\n",
    "    \n",
    "    def errorify_sentences_new(self, data, potential_cols):\n",
    "        \n",
    "        print('Errorifying sentences...')\n",
    "        np.random.seed(42)        \n",
    "        cols = ['text'] + potential_cols + [word + '_words' for word in self.words]\n",
    "        print(cols)\n",
    "        potential_data = data[cols].copy()\n",
    "        potential_data['error'] = np.nan\n",
    "        potential_data['error_type'] = np.nan\n",
    "        potential_data['error_word'] = np.nan\n",
    "        potential_data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        potential_data_correct = data[cols].copy()\n",
    "        potential_data_correct['error'] = data['text'].copy()\n",
    "        potential_data_correct['error_type'] = 'none'\n",
    "        potential_data_correct['error_word'] = np.nan\n",
    "        potential_data_correct.reset_index(drop=True, inplace=True)\n",
    "        for i, row in tqdm(potential_data.iterrows()): # slow method, to be replaced\n",
    "            cols_maybe_errors = [col for col in potential_cols if (row[col] and not np.all(pd.isnull(row[col])))]\n",
    "            error_col = choice(cols_maybe_errors)\n",
    "            # take randomly 1 possible incorrect word or none\n",
    "            # change-in-future: p of 'no error' depends on the number of possible incorrect words\n",
    "            potential_error_words = potential_data.loc[i, error_col]\n",
    "            probabilities = np.empty(len(potential_error_words) + 1)\n",
    "            probabilities[-1] = 0.0\n",
    "            probabilities[:-1] = (1 - probabilities[-1]) / len(potential_error_words)\n",
    "            k = choice(range(len(potential_error_words) + 1), p=probabilities)\n",
    "            potential_data.loc[i, 'error_type'] = error_col.replace('_words_errorified', '')\n",
    "            errorified = potential_data.loc[i, error_col][k]\n",
    "            potential_data.loc[i, 'error_word'] = errorified\n",
    "            original = potential_data.loc[i, error_col.replace('_errorified', '')][k]\n",
    "            potential_data.loc[i, 'error'] = potential_data.loc[i, 'text'].replace(original, errorified)\n",
    "\n",
    "        potential_data = pd.concat([potential_data[['text', 'error', 'error_word', 'error_type']], \n",
    "                                    potential_data_correct[['text', 'error', 'error_word', 'error_type']]], ignore_index=True)\n",
    "        return potential_data[['text', 'error', 'error_word', 'error_type']]\n",
    "    \n",
    "    \n",
    "    def errorify_sentences(self, data, potential_cols):\n",
    "        print('Errorifying sentences...')\n",
    "        np.random.seed(42)\n",
    "        # if more than 1 error, they may interfere with each other\n",
    "        # simple setting: only 1 error\n",
    "        #potential_cols = ['tsya_words_errorified', 'tysya_words_errorified', 'n_words_errorified', 'nn_words_errorified']\n",
    "#         cols = ['text'] + potential_cols + ['tsya_words', 'tysya_words', 'n_words', 'nn_words', 'techenie_words', 'techenii_words'\n",
    "#                                                'ne_words', 'ni_words']\n",
    "        \n",
    "        cols = ['text'] + potential_cols + [word + '_words' for word in self.words]\n",
    "        print(cols)\n",
    "        potential_data = data[cols].copy()\n",
    "        potential_data['error'] = np.nan\n",
    "        potential_data['error_type'] = np.nan\n",
    "        potential_data['error_word'] = np.nan\n",
    "        potential_data.reset_index(drop=True, inplace=True)\n",
    "        for i, row in tqdm(potential_data.iterrows()): # slow method, to be replaced\n",
    "            cols_maybe_errors = [col for col in potential_cols if (row[col] and not np.all(pd.isnull(row[col])))]\n",
    "            error_col = choice(cols_maybe_errors)\n",
    "            # take randomly 1 possible incorrect word or none\n",
    "            # change-in-future: p of 'no error' depends on the number of possible incorrect words\n",
    "            potential_error_words = potential_data.loc[i, error_col]\n",
    "            probabilities = np.empty(len(potential_error_words) + 1)\n",
    "            probabilities[-1] = 0.5\n",
    "            probabilities[:-1] = (1 - probabilities[-1]) / len(potential_error_words)\n",
    "            k = choice(range(len(potential_error_words) + 1), p=probabilities)\n",
    "            if k == len(potential_error_words):\n",
    "                potential_data.loc[i, 'error_type'] = 'none'\n",
    "                potential_data.loc[i, 'error_word'] = np.nan\n",
    "                potential_data.loc[i, 'error'] = potential_data.loc[i, 'text']\n",
    "            else:\n",
    "                potential_data.loc[i, 'error_type'] = error_col.replace('_words_errorified', '')\n",
    "                errorified = potential_data.loc[i, error_col][k]\n",
    "                potential_data.loc[i, 'error_word'] = errorified\n",
    "                original = potential_data.loc[i, error_col.replace('_errorified', '')][k]\n",
    "                potential_data.loc[i, 'error'] = potential_data.loc[i, 'text'].replace(original, errorified)\n",
    "        return potential_data[['text', 'error', 'error_word', 'error_type']]\n",
    "    \n",
    "    def tokenize(self, sentence):\n",
    "        return BasicTokenizer(do_lower_case=False).tokenize(sentence)\n",
    "\n",
    "    def tag_in_conll_format(self, data):\n",
    "        data['tag'] = 'REPLACE_' + data['error_type']\n",
    "        exceptions = dict()\n",
    "        column_names = list(data.columns)\n",
    "        fast_data = data.values.tolist()\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for i in tqdm(range(len(fast_data))):\n",
    "            row = fast_data[i]\n",
    "            error_col_id = column_names.index('error')\n",
    "            error_word_col_id = column_names.index('error_word')                \n",
    "            tag_col_id = column_names.index('tag')\n",
    "            sent_tokens = self.tokenize(row[error_col_id])\n",
    "            sent_labels = [self.KEEP] * len(sent_tokens)\n",
    "            if not pd.isnull(row[error_word_col_id]):\n",
    "                error_word = str(row[error_word_col_id])\n",
    "                try:\n",
    "                    error_word_id = sent_tokens.index(error_word)\n",
    "                    sent_labels[error_word_id] = row[tag_col_id]\n",
    "                except Exception as e:\n",
    "                    print(i, e)\n",
    "                    exceptions[i] = row\n",
    "            tokens.append(sent_tokens)\n",
    "            labels.append(sent_labels)\n",
    "        self.output_num_sentences = len(tokens)\n",
    "        return tokens, labels, exceptions\n",
    "    \n",
    "    def write_dataset_to_file(self, tokens, labels):\n",
    "        with open(self.to_file, 'w') as f:\n",
    "            zipped = list(zip(tokens, labels))\n",
    "            for i in range(len(zipped)):\n",
    "                sentence_tokens = zipped[i][0]\n",
    "                sentence_labels = zipped[i][1]\n",
    "                for j in range(len(sentence_tokens)):\n",
    "                    f.write(sentence_tokens[j] + '\\t' + sentence_labels[j] + '\\n')\n",
    "                f.write('\\n')\n",
    "    \n",
    "    def generate(self, to_file=None, prepared_path = None):\n",
    "        if to_file is not None:\n",
    "            self.to_file = to_file\n",
    "#         self.data = self.select_data()\n",
    "#         print('Data size:', len(self.data))\n",
    "# #         with open('data/all_data_longer_than_10.txt') as f:\n",
    "# #             self.data = f.read().splitlines()\n",
    "#         print('Data size:', len(self.data))\n",
    "#         self.data = self.sentence_tokenize(self.data)\n",
    "#         print('Data size:', len(self.data))\n",
    "#         self.data = self.filter_characters(self.data)\n",
    "#         print('Data size:', len(self.data))\n",
    "# #         if 'nn' in self.generate_type:\n",
    "# #             self.data = self.insert_correct_schitanye(self.data)\n",
    "# #             print('Data size:', len(self.data))\n",
    "#         self.data.to_csv(prepared_path)\n",
    "        \n",
    "        self.data = pd.read_csv(prepared_path, index_col=0)\n",
    "        print(self.data.info(memory_usage=\"deep\"))\n",
    "        if 'nn' in self.generate_type:\n",
    "            self.data = self.add_schitannye(self.data)\n",
    "            print('Data size:', len(self.data))\n",
    "        \n",
    "        if 'tsya' in self.generate_type:\n",
    "            self.data = self.mark_containing_tsya_tysya(self.data)\n",
    "            print('Data size:', len(self.data))\n",
    "        if 'nn' in self.generate_type:\n",
    "            self.data = self.mark_containing_n_nn(self.data)\n",
    "            print('Data size:', len(self.data))\n",
    "        if 'techenie' in self.generate_type:\n",
    "            self.data = self.mark_containing_techenie_ii(self.data)\n",
    "            print('Data size:', len(self.data))\n",
    "        if 'neni_b' in self.generate_type:\n",
    "            self.data = self.mark_containing_ne_ni(self.data)\n",
    "            print('Data size:', len(self.data))\n",
    "        for error_name in self.words:\n",
    "        #for error_name in ['tsya', 'tysya', 'n', 'nn', 'techenie', 'techenii', 'ne', 'ni']:\n",
    "            self.data = self.generate_one_error_type(self.data, error_name)\n",
    "            print('Data size:', len(self.data))\n",
    "        self.data, potential_cols = self.filter_data_by_error_set(self.data)\n",
    "        print('Data size:', len(self.data))\n",
    "        self.data = self.errorify_sentences_new(self.data, potential_cols)\n",
    "        print('Data size:', len(self.data))\n",
    "        tokens, labels, exceptions = self.tag_in_conll_format(self.data)\n",
    "        print('Data size:', len(tokens))\n",
    "        self.data = self.data.drop(exceptions.keys())\n",
    "        self.write_dataset_to_file(tokens, labels)\n",
    "        return self.data, tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "search = re.compile(r'(\\bmany\\b)|(\\bmuch\\b)|(\\blot of\\b)', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 6), match='Lot of'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.search('Lot of.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A title'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'Title'\n",
    "if word.istitle():\n",
    "    word_correct = 'A ' + word[0].lower() + word[1:]\n",
    "word_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset for model retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionaries...\n",
      "CPU times: user 99 ms, sys: 7.99 ms, total: 107 ms\n",
      "Wall time: 105 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generator = SyntheticDatasetGenerator(all_data='dataset_for_retrain_3333.txt', output_file = 'data/dataset_for_retrain_3333_with_mistakes_prob_0.5_full.txt', \n",
    "                                      generate_type=['tsya', 'nn'], data_dir='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting lines larger than 10 symbols...\n",
      "Data size: 17901\n",
      "Data size: 17901\n",
      "Splitting in sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5633it [00:00, 56327.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentences before splitting on ... : 18036\n",
      "Input sentences: 18024\n",
      "Data size: 18024\n",
      "Filtering characters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18024it [00:00, 57693.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 18024\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18024 entries, 0 to 18023\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    18024 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 6.6 MB\n",
      "None\n",
      "Marking tsya/tysya sentences...\n",
      "2571 825\n",
      "Data size: 18024\n",
      "Marking n/nn sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristina/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15456 5472\n",
      "Data size: 18024\n",
      "Generating error tsya ...\n",
      "Data size: 18024\n",
      "Generating error tysya ...\n",
      "Data size: 18024\n",
      "Generating error n ...\n",
      "Data size: 18024\n",
      "Generating error nn ...\n",
      "Data size: 18024\n",
      "Filtering out the sentences that cannot be errorified...\n",
      "Output sentences: 13233\n",
      "Data size: 13233\n",
      "Errorifying sentences...\n",
      "['text', 'tsya_words_errorified', 'tysya_words_errorified', 'n_words_errorified', 'nn_words_errorified', 'tsya_words', 'tysya_words', 'n_words', 'nn_words']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13233it [00:08, 1576.54it/s]\n",
      "  5%|▌         | 680/13233 [00:00<00:01, 6796.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 13233\n",
      "64 'Канне' is not in list\n",
      "65 'Канне' is not in list\n",
      "90 'Гена' is not in list\n",
      "91 'Гена' is not in list\n",
      "92 'Гена' is not in list\n",
      "94 'Гена' is not in list\n",
      "294 'корены' is not in list\n",
      "295 'корены' is not in list\n",
      "296 'корены' is not in list\n",
      "327 'Гена' is not in list\n",
      "328 'Гена' is not in list\n",
      "329 'Гена' is not in list\n",
      "421 'Донне' is not in list\n",
      "422 'Донне' is not in list\n",
      "564 'Гена' is not in list\n",
      "565 'Гена' is not in list\n",
      "566 'Гена' is not in list\n",
      "646 'Донне' is not in list\n",
      "647 'Донне' is not in list\n",
      "778 'Гена' is not in list\n",
      "779 'Гена' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13233/13233 [00:02<00:00, 6442.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 13233\n",
      "CPU times: user 12.4 s, sys: 25 ms, total: 12.4 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generated_data, tokens, labels = generator.generate(to_file='datasets/dataset_for_retrain_3333_with_mistakes_prob_0.5_full.txt', \n",
    "                                                    prepared_path='datasets/prepared_data_for_retrain_3333_with_mistakes_prob_0.5_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "n        8806\n",
       "none     2975\n",
       "nn        322\n",
       "tsya      232\n",
       "tysya     137\n",
       "Name: error_type, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5252\n",
    "print(len(generated_data))\n",
    "generated_data.error_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "n        8664\n",
       "none     3000\n",
       "nn        246\n",
       "tsya      220\n",
       "tysya     150\n",
       "Name: error_type, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3333\n",
    "print(len(generated_data))\n",
    "generated_data.error_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "none     6156\n",
       "n        5714\n",
       "nn        165\n",
       "tsya      150\n",
       "tysya      96\n",
       "Name: error_type, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3333 prob = 0.5\n",
    "print(len(generated_data))\n",
    "generated_data.error_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "n        5788\n",
       "none     1976\n",
       "tsya      163\n",
       "nn        160\n",
       "tysya      99\n",
       "Name: error_type, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2222\n",
    "print(len(generated_data))\n",
    "generated_data.error_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix and analyse files with answeres of model on ruwiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>article_uuid</th>\n",
       "      <th>proc_sentence</th>\n",
       "      <th>corrected</th>\n",
       "      <th>error_types</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1317</td>\n",
       "      <td>27ff3ee6-e469-4f6d-8d89-777ab91aad6b</td>\n",
       "      <td>Иван, влюбленный в Варвару, решает отправится на поиски царевны вместе со своим новым другом Чудо-Юдом.</td>\n",
       "      <td>Иван, влюбленный в Варвару, решает отправиться на поиски царевны вместе со своим новым другом Чудо-Юдом.</td>\n",
       "      <td>['тся -&gt; ться']</td>\n",
       "      <td>[0.99915826]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1485</td>\n",
       "      <td>afd02154-d8bc-4d80-adc8-57986115b203</td>\n",
       "      <td>А в 1943 году Рита Истомина и Михаил Юрьев устроились на санитарный поезд №95, где днём работали в вагонах за медсестёр и санитарок, работали и на кухни, а вечером шли по вагонам с концертом для раненных, пели песни, танцевали.</td>\n",
       "      <td>А в 1943 году Рита Истомина и Михаил Юрьев устроились на санитарный поезд №95, где днём работали в вагонах за медсестёр и санитарок, работали и на кухни, а вечером шли по вагонам с концертом для раненых, пели песни, танцевали.</td>\n",
       "      <td>['нн -&gt; н']</td>\n",
       "      <td>[0.9847805]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1498</td>\n",
       "      <td>afd02154-d8bc-4d80-adc8-57986115b203</td>\n",
       "      <td>8 марта 1882 года был установлен на средства Нижнеисетского завода памятник императору Александру II- 2-х саженная серая мраморная колонна, на верху которой бронзовый бюст императора, а под ним надпись «Царю-освободителю императору Александру II-му», на обратной стороне «8-го марта 1882 года», в венке «8 марта 1861 г.».</td>\n",
       "      <td>8 марта 1882 года был установлен на средства Нижнеисетского завода памятник императору Александру II- 2-х саженая серая мраморная колонна, на верху которой бронзовый бюст императора, а под ним надпись «Царю-освободителю императору Александру II-му», на обратной стороне «8-го марта 1882 года», в венке «8 марта 1861 г.».</td>\n",
       "      <td>['нн -&gt; н']</td>\n",
       "      <td>[0.5428505]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2185</td>\n",
       "      <td>bce48e1a-1d2a-4b8f-9529-cdcf9bc8272c</td>\n",
       "      <td>Страдая бредом величия и именую себя мессией социал-демократии, в ночь на первое апреля 1876 Майнлендер повесился в своей квартире в Оффенбах-на-Майне, используя стопку копий «Философии освобождения» как подставку.</td>\n",
       "      <td>Страдая бредом величия и именную себя мессией социал-демократии, в ночь на первое апреля 1876 Майнлендер повесился в своей квартире в Оффенбах-на-Майне, используя стопку копий «Философии освобождения» как подставку.</td>\n",
       "      <td>['н -&gt; нн', 'н -&gt; нн']</td>\n",
       "      <td>[0.9860064, 0.89134]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3119</td>\n",
       "      <td>4fa6ec1d-d865-4948-b83f-9958ea4e01f4</td>\n",
       "      <td>После поездки наставником юного художника становиться Анатолий Дёмин, который направил юношу на учёбу в Ярославль.</td>\n",
       "      <td>После поездки наставником юного художника становится Анатолий Дёмин, который направил юношу на учёбу в Ярославль.</td>\n",
       "      <td>['ться -&gt; тся']</td>\n",
       "      <td>[0.9997673]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>637309</td>\n",
       "      <td>41e9532f-2243-4a92-9e6a-a1a2e05636bf</td>\n",
       "      <td>По словам лидера группы, это помогает ей сосредоточится и положительно влияет на процесс сочинения.</td>\n",
       "      <td>По словам лидера группы, это помогает ей сосредоточиться и положительно влияет на процесс сочинения.</td>\n",
       "      <td>['тся -&gt; ться']</td>\n",
       "      <td>[0.999123]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>638200</td>\n",
       "      <td>5211ec13-fd3a-4599-87d9-4b60a95e17ba</td>\n",
       "      <td>Высокомерно относится к людям, не верит в возможность мирного сосуществования рас, терпеть не может Юки и Зэро, является объектом особого восхищения старосты Дневного Класса, где учится Юки (причем неоднократно его отвергает).</td>\n",
       "      <td>Высокомерно относиться к людям, не верит в возможность мирного сосуществования рас, терпеть не может Юки и Зэро, является объектом особого восхищения старосты Дневного Класса, где учится Юки (причем неоднократно его отвергает).</td>\n",
       "      <td>['тся -&gt; ться']</td>\n",
       "      <td>[0.750137]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>638271</td>\n",
       "      <td>5211ec13-fd3a-4599-87d9-4b60a95e17ba</td>\n",
       "      <td>Зэро и Итиру были очень близки в детстве, но после того, как Итиру понял, что ему никогда не сравниться с братом, и случайно услышал, что родители предпочитают сделать наследником клана Зэро, а не его, возненавидел брата.</td>\n",
       "      <td>Зэро и Итиру были очень близки в детстве, но после того, как Итиру понял, что ему никогда не сравнится с братом, и случайно услышал, что родители предпочитают сделать наследником клана Зэро, а не его, возненавидел брата.</td>\n",
       "      <td>['ться -&gt; тся']</td>\n",
       "      <td>[0.9819324]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>638327</td>\n",
       "      <td>5211ec13-fd3a-4599-87d9-4b60a95e17ba</td>\n",
       "      <td>Пол ребёнка читателям долгое время был не известен, так как в японской речи он/она говорит о себе обезличено, а на рекламном тизере одной из экстр, а также в описании персонажей в первом томе «Vampire Knight: memories» его/её и Ай объединяли, как «дочери».</td>\n",
       "      <td>Пол ребёнка читателям долгое время был не известен, так как в японской речи он/она говорит о себе обезличенно, а на рекламном тизере одной из экстр, а также в описании персонажей в первом томе «Vampire Knight: memories» его/её и Ай объединяли, как «дочери».</td>\n",
       "      <td>['н -&gt; нн']</td>\n",
       "      <td>[0.9978009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>639797</td>\n",
       "      <td>d0869216-e149-4103-8f66-fdae77542bb6</td>\n",
       "      <td>Архитектура Бийска конца XVIII века была типичной для сибирских городов того времени — деревянные рубленные низкие дома.</td>\n",
       "      <td>Архитектура Бийска конца XVIII века была типичной для сибирских городов того времени — деревянные рубленые низкие дома.</td>\n",
       "      <td>['нн -&gt; н']</td>\n",
       "      <td>[0.87017995]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                          article_uuid  \\\n",
       "0          1317  27ff3ee6-e469-4f6d-8d89-777ab91aad6b   \n",
       "1          1485  afd02154-d8bc-4d80-adc8-57986115b203   \n",
       "2          1498  afd02154-d8bc-4d80-adc8-57986115b203   \n",
       "3          2185  bce48e1a-1d2a-4b8f-9529-cdcf9bc8272c   \n",
       "4          3119  4fa6ec1d-d865-4948-b83f-9958ea4e01f4   \n",
       "..          ...                                   ...   \n",
       "743      637309  41e9532f-2243-4a92-9e6a-a1a2e05636bf   \n",
       "744      638200  5211ec13-fd3a-4599-87d9-4b60a95e17ba   \n",
       "745      638271  5211ec13-fd3a-4599-87d9-4b60a95e17ba   \n",
       "746      638327  5211ec13-fd3a-4599-87d9-4b60a95e17ba   \n",
       "747      639797  d0869216-e149-4103-8f66-fdae77542bb6   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                         proc_sentence  \\\n",
       "0                                                                                                                                                                                                                              Иван, влюбленный в Варвару, решает отправится на поиски царевны вместе со своим новым другом Чудо-Юдом.   \n",
       "1                                                                                                  А в 1943 году Рита Истомина и Михаил Юрьев устроились на санитарный поезд №95, где днём работали в вагонах за медсестёр и санитарок, работали и на кухни, а вечером шли по вагонам с концертом для раненных, пели песни, танцевали.   \n",
       "2    8 марта 1882 года был установлен на средства Нижнеисетского завода памятник императору Александру II- 2-х саженная серая мраморная колонна, на верху которой бронзовый бюст императора, а под ним надпись «Царю-освободителю императору Александру II-му», на обратной стороне «8-го марта 1882 года», в венке «8 марта 1861 г.».   \n",
       "3                                                                                                               Страдая бредом величия и именую себя мессией социал-демократии, в ночь на первое апреля 1876 Майнлендер повесился в своей квартире в Оффенбах-на-Майне, используя стопку копий «Философии освобождения» как подставку.   \n",
       "4                                                                                                                                                                                                                   После поездки наставником юного художника становиться Анатолий Дёмин, который направил юношу на учёбу в Ярославль.   \n",
       "..                                                                                                                                                                                                                                                                                                                                 ...   \n",
       "743                                                                                                                                                                                                                                По словам лидера группы, это помогает ей сосредоточится и положительно влияет на процесс сочинения.   \n",
       "744                                                                                                 Высокомерно относится к людям, не верит в возможность мирного сосуществования рас, терпеть не может Юки и Зэро, является объектом особого восхищения старосты Дневного Класса, где учится Юки (причем неоднократно его отвергает).   \n",
       "745                                                                                                      Зэро и Итиру были очень близки в детстве, но после того, как Итиру понял, что ему никогда не сравниться с братом, и случайно услышал, что родители предпочитают сделать наследником клана Зэро, а не его, возненавидел брата.   \n",
       "746                                                                   Пол ребёнка читателям долгое время был не известен, так как в японской речи он/она говорит о себе обезличено, а на рекламном тизере одной из экстр, а также в описании персонажей в первом томе «Vampire Knight: memories» его/её и Ай объединяли, как «дочери».   \n",
       "747                                                                                                                                                                                                           Архитектура Бийска конца XVIII века была типичной для сибирских городов того времени — деревянные рубленные низкие дома.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                            corrected  \\\n",
       "0                                                                                                                                                                                                                            Иван, влюбленный в Варвару, решает отправиться на поиски царевны вместе со своим новым другом Чудо-Юдом.   \n",
       "1                                                                                                  А в 1943 году Рита Истомина и Михаил Юрьев устроились на санитарный поезд №95, где днём работали в вагонах за медсестёр и санитарок, работали и на кухни, а вечером шли по вагонам с концертом для раненых, пели песни, танцевали.   \n",
       "2    8 марта 1882 года был установлен на средства Нижнеисетского завода памятник императору Александру II- 2-х саженая серая мраморная колонна, на верху которой бронзовый бюст императора, а под ним надпись «Царю-освободителю императору Александру II-му», на обратной стороне «8-го марта 1882 года», в венке «8 марта 1861 г.».   \n",
       "3                                                                                                             Страдая бредом величия и именную себя мессией социал-демократии, в ночь на первое апреля 1876 Майнлендер повесился в своей квартире в Оффенбах-на-Майне, используя стопку копий «Философии освобождения» как подставку.   \n",
       "4                                                                                                                                                                                                                   После поездки наставником юного художника становится Анатолий Дёмин, который направил юношу на учёбу в Ярославль.   \n",
       "..                                                                                                                                                                                                                                                                                                                                ...   \n",
       "743                                                                                                                                                                                                                              По словам лидера группы, это помогает ей сосредоточиться и положительно влияет на процесс сочинения.   \n",
       "744                                                                                               Высокомерно относиться к людям, не верит в возможность мирного сосуществования рас, терпеть не может Юки и Зэро, является объектом особого восхищения старосты Дневного Класса, где учится Юки (причем неоднократно его отвергает).   \n",
       "745                                                                                                      Зэро и Итиру были очень близки в детстве, но после того, как Итиру понял, что ему никогда не сравнится с братом, и случайно услышал, что родители предпочитают сделать наследником клана Зэро, а не его, возненавидел брата.   \n",
       "746                                                                 Пол ребёнка читателям долгое время был не известен, так как в японской речи он/она говорит о себе обезличенно, а на рекламном тизере одной из экстр, а также в описании персонажей в первом томе «Vampire Knight: memories» его/её и Ай объединяли, как «дочери».   \n",
       "747                                                                                                                                                                                                           Архитектура Бийска конца XVIII века была типичной для сибирских городов того времени — деревянные рубленые низкие дома.   \n",
       "\n",
       "                error_types           probability  \n",
       "0           ['тся -> ться']          [0.99915826]  \n",
       "1               ['нн -> н']           [0.9847805]  \n",
       "2               ['нн -> н']           [0.5428505]  \n",
       "3    ['н -> нн', 'н -> нн']  [0.9860064, 0.89134]  \n",
       "4           ['ться -> тся']           [0.9997673]  \n",
       "..                      ...                   ...  \n",
       "743         ['тся -> ться']            [0.999123]  \n",
       "744         ['тся -> ться']            [0.750137]  \n",
       "745         ['ться -> тся']           [0.9819324]  \n",
       "746             ['н -> нн']           [0.9978009]  \n",
       "747             ['нн -> н']          [0.87017995]  \n",
       "\n",
       "[748 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ruwiki_2018_09_25_answered_fl_2_doubled_sent.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>article_uuid</th>\n",
       "      <th>proc_sentence</th>\n",
       "      <th>corrected</th>\n",
       "      <th>error_types</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Unnamed: 0.1, article_uuid, proc_sentence, corrected, error_types, probability]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlin = re.compile(r'\\bдлин[а|у|ы|е|ой]', flags=re.IGNORECASE)\n",
    "dlinn = re.compile(r'\\bдлинн[а|у|ы|е|ой]', flags=re.IGNORECASE)\n",
    "#indices_dlinn = df[df['corrected'].str.contains(dlinn)].index.to_numpy()\n",
    "df[df['corrected'].str.contains(dlinn)]\n",
    "#df = df[~df.index.isin(indices_dlinn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'article_uuid', 'proc_sentence', 'corrected',\n",
      "       'error_types', 'probability'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0.1'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2d0b16423f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4165\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4166\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4167\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4168\u001b[0m         )\n\u001b[1;32m   4169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3876\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3877\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3878\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3910\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3911\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3912\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3913\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5275\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5276\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5277\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 0.1'] not found in axis\""
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df = df.drop(['Unnamed: 0.1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_uuid</th>\n",
       "      <th>proc_sentence</th>\n",
       "      <th>corrected</th>\n",
       "      <th>error_types</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>27ff3ee6-e469-4f6d-8d89-777ab91aad6b</td>\n",
       "      <td>Иван, влюбленный в Варвару, решает отправится на поиски царевны вместе со своим новым другом Чудо-Юдом.</td>\n",
       "      <td>Иван, влюбленный в Варвару, решает отправиться на поиски царевны вместе со своим новым другом Чудо-Юдом.</td>\n",
       "      <td>['тся -&gt; ться']</td>\n",
       "      <td>[0.99915826]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>afd02154-d8bc-4d80-adc8-57986115b203</td>\n",
       "      <td>А в 1943 году Рита Истомина и Михаил Юрьев устроились на санитарный поезд №95, где днём работали в вагонах за медсестёр и санитарок, работали и на кухни, а вечером шли по вагонам с концертом для раненных, пели песни, танцевали.</td>\n",
       "      <td>А в 1943 году Рита Истомина и Михаил Юрьев устроились на санитарный поезд №95, где днём работали в вагонах за медсестёр и санитарок, работали и на кухни, а вечером шли по вагонам с концертом для раненых, пели песни, танцевали.</td>\n",
       "      <td>['нн -&gt; н']</td>\n",
       "      <td>[0.9847805]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>afd02154-d8bc-4d80-adc8-57986115b203</td>\n",
       "      <td>8 марта 1882 года был установлен на средства Нижнеисетского завода памятник императору Александру II- 2-х саженная серая мраморная колонна, на верху которой бронзовый бюст императора, а под ним надпись «Царю-освободителю императору Александру II-му», на обратной стороне «8-го марта 1882 года», в венке «8 марта 1861 г.».</td>\n",
       "      <td>8 марта 1882 года был установлен на средства Нижнеисетского завода памятник императору Александру II- 2-х саженая серая мраморная колонна, на верху которой бронзовый бюст императора, а под ним надпись «Царю-освободителю императору Александру II-му», на обратной стороне «8-го марта 1882 года», в венке «8 марта 1861 г.».</td>\n",
       "      <td>['нн -&gt; н']</td>\n",
       "      <td>[0.5428505]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>bce48e1a-1d2a-4b8f-9529-cdcf9bc8272c</td>\n",
       "      <td>Страдая бредом величия и именую себя мессией социал-демократии, в ночь на первое апреля 1876 Майнлендер повесился в своей квартире в Оффенбах-на-Майне, используя стопку копий «Философии освобождения» как подставку.</td>\n",
       "      <td>Страдая бредом величия и именную себя мессией социал-демократии, в ночь на первое апреля 1876 Майнлендер повесился в своей квартире в Оффенбах-на-Майне, используя стопку копий «Философии освобождения» как подставку.</td>\n",
       "      <td>['н -&gt; нн', 'н -&gt; нн']</td>\n",
       "      <td>[0.9860064, 0.89134]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>4fa6ec1d-d865-4948-b83f-9958ea4e01f4</td>\n",
       "      <td>После поездки наставником юного художника становиться Анатолий Дёмин, который направил юношу на учёбу в Ярославль.</td>\n",
       "      <td>После поездки наставником юного художника становится Анатолий Дёмин, который направил юношу на учёбу в Ярославль.</td>\n",
       "      <td>['ться -&gt; тся']</td>\n",
       "      <td>[0.9997673]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article_uuid  \\\n",
       "initial_index                                         \n",
       "1317           27ff3ee6-e469-4f6d-8d89-777ab91aad6b   \n",
       "1485           afd02154-d8bc-4d80-adc8-57986115b203   \n",
       "1498           afd02154-d8bc-4d80-adc8-57986115b203   \n",
       "2185           bce48e1a-1d2a-4b8f-9529-cdcf9bc8272c   \n",
       "3119           4fa6ec1d-d865-4948-b83f-9958ea4e01f4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                   proc_sentence  \\\n",
       "initial_index                                                                                                                                                                                                                                                                                                                                      \n",
       "1317                                                                                                                                                                                                                                     Иван, влюбленный в Варвару, решает отправится на поиски царевны вместе со своим новым другом Чудо-Юдом.   \n",
       "1485                                                                                                         А в 1943 году Рита Истомина и Михаил Юрьев устроились на санитарный поезд №95, где днём работали в вагонах за медсестёр и санитарок, работали и на кухни, а вечером шли по вагонам с концертом для раненных, пели песни, танцевали.   \n",
       "1498           8 марта 1882 года был установлен на средства Нижнеисетского завода памятник императору Александру II- 2-х саженная серая мраморная колонна, на верху которой бронзовый бюст императора, а под ним надпись «Царю-освободителю императору Александру II-му», на обратной стороне «8-го марта 1882 года», в венке «8 марта 1861 г.».   \n",
       "2185                                                                                                                      Страдая бредом величия и именую себя мессией социал-демократии, в ночь на первое апреля 1876 Майнлендер повесился в своей квартире в Оффенбах-на-Майне, используя стопку копий «Философии освобождения» как подставку.   \n",
       "3119                                                                                                                                                                                                                          После поездки наставником юного художника становиться Анатолий Дёмин, который направил юношу на учёбу в Ярославль.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                      corrected  \\\n",
       "initial_index                                                                                                                                                                                                                                                                                                                                     \n",
       "1317                                                                                                                                                                                                                                   Иван, влюбленный в Варвару, решает отправиться на поиски царевны вместе со своим новым другом Чудо-Юдом.   \n",
       "1485                                                                                                         А в 1943 году Рита Истомина и Михаил Юрьев устроились на санитарный поезд №95, где днём работали в вагонах за медсестёр и санитарок, работали и на кухни, а вечером шли по вагонам с концертом для раненых, пели песни, танцевали.   \n",
       "1498           8 марта 1882 года был установлен на средства Нижнеисетского завода памятник императору Александру II- 2-х саженая серая мраморная колонна, на верху которой бронзовый бюст императора, а под ним надпись «Царю-освободителю императору Александру II-му», на обратной стороне «8-го марта 1882 года», в венке «8 марта 1861 г.».   \n",
       "2185                                                                                                                    Страдая бредом величия и именную себя мессией социал-демократии, в ночь на первое апреля 1876 Майнлендер повесился в своей квартире в Оффенбах-на-Майне, используя стопку копий «Философии освобождения» как подставку.   \n",
       "3119                                                                                                                                                                                                                          После поездки наставником юного художника становится Анатолий Дёмин, который направил юношу на учёбу в Ярославль.   \n",
       "\n",
       "                          error_types           probability  \n",
       "initial_index                                                \n",
       "1317                  ['тся -> ться']          [0.99915826]  \n",
       "1485                      ['нн -> н']           [0.9847805]  \n",
       "1498                      ['нн -> н']           [0.5428505]  \n",
       "2185           ['н -> нн', 'н -> нн']  [0.9860064, 0.89134]  \n",
       "3119                  ['ться -> тся']           [0.9997673]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = df.columns.tolist()\n",
    "cols = ['initial_index'] + cols[1:]\n",
    "df.columns = cols\n",
    "df = df.set_index('initial_index')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if some sentences were not fixed by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.proc_sentence == df.corrected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.proc_sentence != df.corrected]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"['н -> нн', 'н -> нн']\", \"['н -> нн']\", \"['нн -> н']\",\n",
       "       \"['тся -> ться', 'тся -> ться']\", \"['тся -> ться']\",\n",
       "       \"['ться -> тся']\"], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df.error_types.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save fixed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ruwiki_2018_09_25_answered_fl_2_doubled_sent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse comparisons of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mihail_acc</th>\n",
       "      <th>Mihail_p</th>\n",
       "      <th>Mihail_r</th>\n",
       "      <th>Mihail_f1</th>\n",
       "      <th>Gramota_acc</th>\n",
       "      <th>Gramota_p</th>\n",
       "      <th>Gramota_r</th>\n",
       "      <th>Gramota_f1</th>\n",
       "      <th>Full_acc</th>\n",
       "      <th>Full_p</th>\n",
       "      <th>Full_r</th>\n",
       "      <th>Full_f1</th>\n",
       "      <th>Tsya_acc</th>\n",
       "      <th>Tsya_p</th>\n",
       "      <th>Tsya_r</th>\n",
       "      <th>Tsya_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FL_hardsoft_1</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.774515</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.930693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FL_hardsoft_2</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.842767</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.709302</td>\n",
       "      <td>0.755284</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>0.773414</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.930693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FL_hardsoft_2_70_30</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.659341</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.758663</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>0.774390</td>\n",
       "      <td>0.951327</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.945274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POW_hardsoft_1</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.718563</td>\n",
       "      <td>0.764900</td>\n",
       "      <td>0.748503</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.776398</td>\n",
       "      <td>0.924779</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.917874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POW_hardsoft_2</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.752252</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DP</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.752079</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.766871</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.932692</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.941748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Mihail_acc  Mihail_p  Mihail_r  Mihail_f1  \\\n",
       "0        FL_hardsoft_1    0.831081  0.822785  0.855263   0.838710   \n",
       "1        FL_hardsoft_2    0.831081  0.807229  0.881579   0.842767   \n",
       "2  FL_hardsoft_2_70_30    0.837838  0.817073  0.881579   0.848101   \n",
       "3       POW_hardsoft_1    0.831081  0.822785  0.855263   0.838710   \n",
       "4       POW_hardsoft_2    0.837838  0.833333  0.855263   0.844156   \n",
       "5                   DP    0.831081  0.822785  0.855263   0.838710   \n",
       "\n",
       "   Gramota_acc  Gramota_p  Gramota_r  Gramota_f1  Full_acc    Full_p  \\\n",
       "0     0.717949   0.701149   0.772152    0.734940  0.774515  0.759036   \n",
       "1     0.679487   0.655914   0.772152    0.709302  0.755284  0.727273   \n",
       "2     0.679487   0.659341   0.759494    0.705882  0.758663  0.734104   \n",
       "3     0.698718   0.681818   0.759494    0.718563  0.764900  0.748503   \n",
       "4     0.666667   0.655172   0.721519    0.686747  0.752252  0.739394   \n",
       "5     0.673077   0.652174   0.759494    0.701754  0.752079  0.730994   \n",
       "\n",
       "     Full_r   Full_f1  Tsya_acc    Tsya_p    Tsya_r   Tsya_f1  \n",
       "0  0.812903  0.785047  0.938053  0.940000  0.921569  0.930693  \n",
       "1  0.825806  0.773414  0.938053  0.940000  0.921569  0.930693  \n",
       "2  0.819355  0.774390  0.951327  0.959596  0.931373  0.945274  \n",
       "3  0.806452  0.776398  0.924779  0.904762  0.931373  0.917874  \n",
       "4  0.787097  0.762500  0.920354  0.888889  0.941176  0.914286  \n",
       "5  0.806452  0.766871  0.946903  0.932692  0.950980  0.941748  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('comparison_universal_default_incorrect.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mihail_acc</th>\n",
       "      <th>Mihail_p</th>\n",
       "      <th>Mihail_r</th>\n",
       "      <th>Mihail_f1</th>\n",
       "      <th>Gramota_acc</th>\n",
       "      <th>Gramota_p</th>\n",
       "      <th>Gramota_r</th>\n",
       "      <th>Gramota_f1</th>\n",
       "      <th>Full_acc</th>\n",
       "      <th>Full_p</th>\n",
       "      <th>Full_r</th>\n",
       "      <th>Full_f1</th>\n",
       "      <th>Tsya_acc</th>\n",
       "      <th>Tsya_p</th>\n",
       "      <th>Tsya_r</th>\n",
       "      <th>Tsya_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fl_hardsoft_correct_1set</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.792040</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.872727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fl_hardsoft_correct_2set</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.757113</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.872727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fl_hardsoft_correct_2set_70_30</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.739744</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853556</td>\n",
       "      <td>0.884956</td>\n",
       "      <td>0.822034</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.881818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fl_hardsoft_correct_2set_prob_0.5</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.792720</td>\n",
       "      <td>0.801724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fl_hardsoft_correct__doubled_sent_2set</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.798220</td>\n",
       "      <td>0.806723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893023</td>\n",
       "      <td>0.871681</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.871111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fl_hardsoft_correct_2set_retrained_2222_with_m...</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.929134</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.778651</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.871560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fl_hardsoft_correct_2set_retrained_3333_with_m...</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.797031</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.873874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fl_hardsoft_correct_2set_retrained_5252_with_m...</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.780303</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881818</td>\n",
       "      <td>0.858407</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.855856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fl_hardsoft_correct_2set_retrained_3333_with_m...</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.806573</td>\n",
       "      <td>0.811475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.895928</td>\n",
       "      <td>0.871681</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.871111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fl_hardsoft_correct_2set_retrained_3332_with_m...</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.929134</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.810873</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.871681</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.872247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pow_hardsoft_correct_1set</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.755195</td>\n",
       "      <td>0.757353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.861925</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.805085</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pow_hardsoft_correct_2set</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.792793</td>\n",
       "      <td>0.754829</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.795082</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.866071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fl_hardsoft_correct_universal_magazines_dp</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.747243</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.884956</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.882883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pow_hardsoft_correct_magazines_dp</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.786657</td>\n",
       "      <td>0.789062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882096</td>\n",
       "      <td>0.884956</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.882883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  Mihail_acc  Mihail_p  \\\n",
       "0                            fl_hardsoft_correct_1set    0.850746  0.850746   \n",
       "1                            fl_hardsoft_correct_2set    0.821918  0.821918   \n",
       "2                      fl_hardsoft_correct_2set_70_30    0.833333  0.833333   \n",
       "3                   fl_hardsoft_correct_2set_prob_0.5    0.850746  0.850746   \n",
       "4              fl_hardsoft_correct__doubled_sent_2set    0.865672  0.865672   \n",
       "5   fl_hardsoft_correct_2set_retrained_2222_with_m...    0.867647  0.867647   \n",
       "6   fl_hardsoft_correct_2set_retrained_3333_with_m...    0.892308  0.892308   \n",
       "7   fl_hardsoft_correct_2set_retrained_5252_with_m...    0.893939  0.893939   \n",
       "8   fl_hardsoft_correct_2set_retrained_3333_with_m...    0.906250  0.906250   \n",
       "9   fl_hardsoft_correct_2set_retrained_3332_with_m...    0.867647  0.867647   \n",
       "10                          pow_hardsoft_correct_1set    0.828571  0.828571   \n",
       "11                          pow_hardsoft_correct_2set    0.852941  0.852941   \n",
       "12         fl_hardsoft_correct_universal_magazines_dp    0.838235  0.838235   \n",
       "13                  pow_hardsoft_correct_magazines_dp    0.863636  0.863636   \n",
       "\n",
       "    Mihail_r  Mihail_f1  Gramota_acc  Gramota_p  Gramota_r  Gramota_f1  \\\n",
       "0        1.0   0.919355     0.733333   0.733333        1.0    0.846154   \n",
       "1        1.0   0.902256     0.692308   0.692308        1.0    0.818182   \n",
       "2        1.0   0.909091     0.646154   0.646154        1.0    0.785047   \n",
       "3        1.0   0.919355     0.734694   0.734694        1.0    0.847059   \n",
       "4        1.0   0.928000     0.730769   0.730769        1.0    0.844444   \n",
       "5        1.0   0.929134     0.689655   0.689655        1.0    0.816327   \n",
       "6        1.0   0.943089     0.701754   0.701754        1.0    0.824742   \n",
       "7        1.0   0.944000     0.666667   0.666667        1.0    0.800000   \n",
       "8        1.0   0.950820     0.706897   0.706897        1.0    0.828283   \n",
       "9        1.0   0.929134     0.754098   0.754098        1.0    0.859813   \n",
       "10       1.0   0.906250     0.681818   0.681818        1.0    0.810811   \n",
       "11       1.0   0.920635     0.656716   0.656716        1.0    0.792793   \n",
       "12       1.0   0.912000     0.656250   0.656250        1.0    0.792453   \n",
       "13       1.0   0.926829     0.709677   0.709677        1.0    0.830189   \n",
       "\n",
       "    Full_acc    Full_p  Full_r   Full_f1  Tsya_acc    Tsya_p    Tsya_r  \\\n",
       "0   0.792040  0.795276     1.0  0.885965  0.876106  0.813559  0.941176   \n",
       "1   0.757113  0.760870     1.0  0.864198  0.876106  0.813559  0.941176   \n",
       "2   0.739744  0.744526     1.0  0.853556  0.884956  0.822034  0.950980   \n",
       "3   0.792720  0.801724     1.0  0.889952  0.876106  0.803279  0.960784   \n",
       "4   0.798220  0.806723     1.0  0.893023  0.871681  0.796748  0.960784   \n",
       "5   0.778651  0.785714     1.0  0.880000  0.876106  0.818966  0.931373   \n",
       "6   0.797031  0.803279     1.0  0.890909  0.876106  0.808333  0.950980   \n",
       "7   0.780303  0.788618     1.0  0.881818  0.858407  0.791667  0.931373   \n",
       "8   0.806573  0.811475     1.0  0.895928  0.871681  0.796748  0.960784   \n",
       "9   0.810873  0.813953     1.0  0.897436  0.871681  0.792000  0.970588   \n",
       "10  0.755195  0.757353     1.0  0.861925  0.867257  0.805085  0.931373   \n",
       "11  0.754829  0.755556     1.0  0.860759  0.867257  0.795082  0.950980   \n",
       "12  0.747243  0.750000     1.0  0.857143  0.884956  0.816667  0.960784   \n",
       "13  0.786657  0.789062     1.0  0.882096  0.884956  0.816667  0.960784   \n",
       "\n",
       "     Tsya_f1  \n",
       "0   0.872727  \n",
       "1   0.872727  \n",
       "2   0.881818  \n",
       "3   0.875000  \n",
       "4   0.871111  \n",
       "5   0.871560  \n",
       "6   0.873874  \n",
       "7   0.855856  \n",
       "8   0.871111  \n",
       "9   0.872247  \n",
       "10  0.863636  \n",
       "11  0.866071  \n",
       "12  0.882883  \n",
       "13  0.882883  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('comparison_universal_default_incorrect.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare answers of  fl_hardsoft_1_universal & fl_hardsoft_1_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_sent</th>\n",
       "      <th>fl_hs_1_universal</th>\n",
       "      <th>fl_hs_1_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Свежий номер \"Комсомольской правды\" к вашему завтраку (количество ежедневных экземпляров ограничено).</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Свежий номер \"Комсомольской правды\" к вашему завтраку (количество ежедневных экземпляров ограниченно).</td>\n",
       "      <td>Свежий номер \"Комсомольской правды\" к вашему завтраку (количество ежедневных экземпляров ограничено).</td>\n",
       "      <td>Свежий номер \"Комсомольской правды\" к вашему завтраку (количество ежедневных экземпляров ограничено).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Количество призов ограничено - 50 000 шт.</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Количество призов ограниченно - 50 000 шт.</td>\n",
       "      <td>Количество призов ограничено - 50 000 шт.</td>\n",
       "      <td>Количество призов ограничено - 50 000 шт.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Если нет, то почему же внимание автора статей изначально не привлек вопрос, насколько обосновано недовольство и жалобы тех \"не согласных ни с чем граждан\", которые и дали почву для подобных обвинений в мой адрес?</td>\n",
       "      <td>Если нет, то почему же внимание автора статей изначально не привлек вопрос, насколько обоснованно недовольство и жалобы тех \"не согласных ни с чем граждан\", которые и дали почву для подобных обвинений в мой адрес?</td>\n",
       "      <td>Если нет, то почему же внимание автора статей изначально не привлек вопрос, насколько обоснованно недовольство и жалобы тех \"не согласных ни с чем граждан\", которые и дали почву для подобных обвинений в мой адрес?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Что касается конечностей и их длины, в частности: возможно дело не в \"площади потерь тепла\" с конечностей, а в том, что в теплых регионах обмен веществ происходит быстрее, соответственно это отражается на активности,</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Остались считанные дни!</td>\n",
       "      <td>Остались считаные дни!</td>\n",
       "      <td>Остались считаные дни!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Остались считаные дни!</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>В смысле она вообще не выглядела простужено.</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>В смысле она вообще не выглядела простуженно.</td>\n",
       "      <td>Correct</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                original_sent  \\\n",
       "0                                                                                                                       Свежий номер \"Комсомольской правды\" к вашему завтраку (количество ежедневных экземпляров ограничено).   \n",
       "1                                                                                                                      Свежий номер \"Комсомольской правды\" к вашему завтраку (количество ежедневных экземпляров ограниченно).   \n",
       "2                                                                                                                                                                                   Количество призов ограничено - 50 000 шт.   \n",
       "3                                                                                                                                                                                  Количество призов ограниченно - 50 000 шт.   \n",
       "4        Если нет, то почему же внимание автора статей изначально не привлек вопрос, насколько обосновано недовольство и жалобы тех \"не согласных ни с чем граждан\", которые и дали почву для подобных обвинений в мой адрес?   \n",
       "..                                                                                                                                                                                                                        ...   \n",
       "301  Что касается конечностей и их длины, в частности: возможно дело не в \"площади потерь тепла\" с конечностей, а в том, что в теплых регионах обмен веществ происходит быстрее, соответственно это отражается на активности,   \n",
       "302                                                                                                                                                                                                   Остались считанные дни!   \n",
       "303                                                                                                                                                                                                    Остались считаные дни!   \n",
       "304                                                                                                                                                                              В смысле она вообще не выглядела простужено.   \n",
       "305                                                                                                                                                                             В смысле она вообще не выглядела простуженно.   \n",
       "\n",
       "                                                                                                                                                                                                         fl_hs_1_universal  \\\n",
       "0                                                                                                                                                                                                                  Correct   \n",
       "1                                                                                                                    Свежий номер \"Комсомольской правды\" к вашему завтраку (количество ежедневных экземпляров ограничено).   \n",
       "2                                                                                                                                                                                                                  Correct   \n",
       "3                                                                                                                                                                                Количество призов ограничено - 50 000 шт.   \n",
       "4    Если нет, то почему же внимание автора статей изначально не привлек вопрос, насколько обоснованно недовольство и жалобы тех \"не согласных ни с чем граждан\", которые и дали почву для подобных обвинений в мой адрес?   \n",
       "..                                                                                                                                                                                                                     ...   \n",
       "301                                                                                                                                                                                                                Correct   \n",
       "302                                                                                                                                                                                                 Остались считаные дни!   \n",
       "303                                                                                                                                                                                                                Correct   \n",
       "304                                                                                                                                                                                                                Correct   \n",
       "305                                                                                                                                                                                                                Correct   \n",
       "\n",
       "                                                                                                                                                                                                               fl_hs_1_old  \n",
       "0                                                                                                                                                                                                                  Correct  \n",
       "1                                                                                                                    Свежий номер \"Комсомольской правды\" к вашему завтраку (количество ежедневных экземпляров ограничено).  \n",
       "2                                                                                                                                                                                                                  Correct  \n",
       "3                                                                                                                                                                                Количество призов ограничено - 50 000 шт.  \n",
       "4    Если нет, то почему же внимание автора статей изначально не привлек вопрос, насколько обоснованно недовольство и жалобы тех \"не согласных ни с чем граждан\", которые и дали почву для подобных обвинений в мой адрес?  \n",
       "..                                                                                                                                                                                                                     ...  \n",
       "301                                                                                                                                                                                                                Correct  \n",
       "302                                                                                                                                                                                                 Остались считаные дни!  \n",
       "303                                                                                                                                                                                                                Correct  \n",
       "304                                                                                                                                                                                                                Correct  \n",
       "305                                                                                                                                                                                                                Correct  \n",
       "\n",
       "[306 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('compare_fl_hardsoft_1.csv', index_col=0)\n",
    "#df = df.drop(['Unnamed: 0'], axis=1)\n",
    "#df.to_csv('compare_fl_hardsoft_1.csv')\n",
    "#df[~df.fl_hs_1_universal.str.contains('Correct')]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all считаные/считанные sentences into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('prepared_data_full_endings.csv', index_col=0)\n",
    "# data2 = pd.read_csv('news_prepared_data_full_endings.csv', index_col=0)\n",
    "# schitan = re.compile(r'\\bсчитан[ые|ыми|ое]', flags=re.IGNORECASE)\n",
    "# schitann = re.compile(r'\\bсчитанн[ые|ыми|ое]', flags=re.IGNORECASE)\n",
    "# data['n_case'] = data['text'].str.contains(schitan, regex=True)\n",
    "# data['schitanye'] = data[data['n_case'].fillna(False)]['text']\n",
    "# data['nn_case']  = data['text'].str.contains(schitann, regex=True)\n",
    "# data['schitannye'] = data[data['nn_case'].fillna(False)]['text']\n",
    "# sizes = data.count().to_numpy()\n",
    "# k = sizes[4]-sizes[2]\n",
    "# print(k)\n",
    "# schitan_data = data['schitanye'].dropna().to_numpy()\n",
    "# schitann_data = data['schitannye'].dropna().to_numpy()\n",
    "# data2['n_case'] = data2['text'].str.contains(schitan, regex=True)\n",
    "# data2['schitanye'] = data2[data2['n_case'].fillna(False)]['text']\n",
    "# data2['nn_case']  = data2['text'].str.contains(schitann, regex=True)\n",
    "# data2['schitannye'] = data2[data2['nn_case'].fillna(False)]['text']\n",
    "# sizes = data2.count().to_numpy()\n",
    "# k2 = sizes[4]-sizes[2]\n",
    "# print(k2)\n",
    "# schitan_data2 = data2['schitanye'].dropna().to_numpy()\n",
    "# schitann_data2 = data2['schitannye'].dropna().to_numpy()\n",
    "# array1 = np.concatenate((schitan_data, schitann_data), axis=None)\n",
    "# array2 = np.concatenate((schitan_data2, schitann_data2), axis=None)\n",
    "# with open(\"all_shcitanye_sentences_magazines.txt\", \"w\") as f:\n",
    "#     for sentence in array1:\n",
    "#         f.write(sentence)\n",
    "#         f.write('\\n')\n",
    "# with open(\"all_shcitanye_sentences_news.txt\", \"w\") as f:\n",
    "#     for sentence in array2:\n",
    "#         f.write(sentence)\n",
    "#         f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all \"Длинна/Длина\" sentences into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristina/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "/home/kristina/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "-1971\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('datasets/prepared_data_hardsoft_correct.csv', index_col=0)\n",
    "# data2 = pd.read_csv('datasets/news_prepared_data_hardsoft_correct.csv', index_col=0)\n",
    "# dlin = re.compile(r'\\bдлин(а|у|ы|е|(ой))(\\b|\\.|\\,)', flags=re.IGNORECASE)\n",
    "# dlinn = re.compile(r'\\bдлинн(а|у|ы|е|(ой))(\\b|\\.|\\,)', flags=re.IGNORECASE)\n",
    "# data['n_case'] = data['text'].str.contains(dlin, regex=True)\n",
    "# data['dlina'] = data[data['n_case'].fillna(False)]['text']\n",
    "# data['nn_case']  = data['text'].str.contains(dlinn, regex=True)\n",
    "# data['dlinna'] = data[data['nn_case'].fillna(False)]['text']\n",
    "# sizes = data.count().to_numpy()\n",
    "# k = sizes[4]-sizes[2]\n",
    "# print(k)\n",
    "# dlin_data = data['dlina'].dropna().to_numpy()\n",
    "# dlinn_data = data['dlinna'].dropna().to_numpy()\n",
    "# data2['n_case'] = data2['text'].str.contains(dlin, regex=True)\n",
    "# data2['dlina'] = data2[data2['n_case'].fillna(False)]['text']\n",
    "# data2['nn_case']  = data2['text'].str.contains(dlinn, regex=True)\n",
    "# data2['dlinna'] = data2[data2['nn_case'].fillna(False)]['text']\n",
    "# sizes = data2.count().to_numpy()\n",
    "# k2 = sizes[4]-sizes[2]\n",
    "# print(k2)\n",
    "# dlin_data2 = data2['dlina'].dropna().to_numpy()\n",
    "# dlinn_data2 = data2['dlinna'].dropna().to_numpy()\n",
    "# # To different files for Magazines and News\n",
    "# # array1 = np.concatenate((dlin_data, dlinn_data), axis=None)\n",
    "# # array2 = np.concatenate((dlin_data2, dlinn_data2), axis=None)\n",
    "# # with open(\"dlina_sentences_magazines.txt\", \"w\") as f:\n",
    "# #     for sentence in array1:\n",
    "# #         f.write(sentence)\n",
    "# #         f.write('\\n')\n",
    "# # with open(\"dlina_sentences_news.txt\", \"w\") as f:\n",
    "# #     for sentence in array2:\n",
    "# #         f.write(sentence)\n",
    "# #         f.write('\\n')\n",
    "\n",
    "# # To 1 file only \"длина\" for both sets\n",
    "# array1 = np.concatenate((dlin_data, dlin_data2), axis=None)\n",
    "# with open(\"all_dliNa_sent.txt\", \"w\") as f:\n",
    "#     for sentence in array1:\n",
    "#         f.write(sentence)\n",
    "#         f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       16135507\n",
       "n_case     16135507\n",
       "dlina          3436\n",
       "nn_case    16135507\n",
       "dlinna         3501\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.count())\n",
    "print(sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get statistics of generated texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(input_file, outputfile_tsya, outputfile_nn):\n",
    "#     print(generated_data.error_word.str.lower().value_counts())\n",
    "#     df = generated_data.error_word.str.lower().value_counts()\n",
    "#     df = df.reset_index()\n",
    "#     cols = ['incorrect_word', 'value_count']\n",
    "#     df.columns = cols\n",
    "#     df.to_csv(\"Statistics_magazines.csv\", index=False)\n",
    "    dict_tsya = {}\n",
    "    dict_nn = {}\n",
    "    tsya_data = pd.DataFrame(columns=['word', 'value_count', 'pair_word', 'value_cout_pair'])\n",
    "    nn_data = pd.DataFrame(columns=['word', 'value_count', 'pair_word', 'value_cout_pair'])\n",
    "\n",
    "    nn_search = re.compile(r'\\wнн([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|'\n",
    "                                   r'ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b',\n",
    "                                   re.IGNORECASE)  # the words, which contain \"н\" in the middle or in the end of word\n",
    "    n_search = re.compile(r'[аоэеиыуёюя]н([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|'\n",
    "                                  r'ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b',\n",
    "                                  re.IGNORECASE)\n",
    "    pattern_nn = re.compile(\n",
    "                r'(?-i:нн)'\n",
    "                r'(?=([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b)',\n",
    "                re.IGNORECASE)\n",
    "    pattern_n = re.compile(\n",
    "                r'(?<=[аоэеиыуёюя])(?-i:н)'\n",
    "                r'(?=([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b)',\n",
    "                re.IGNORECASE)\n",
    "    \n",
    "    with open(input_file, 'r') as f:\n",
    "        line = f.readline().strip()\n",
    "        line_words = line.split()\n",
    "\n",
    "        while line:\n",
    "            if len(line_words) > 0:\n",
    "                word = line_words[0].lower()\n",
    "                if re.search('(тся)|(ться)',word) is not None:\n",
    "                    if word not in dict_tsya:\n",
    "                        dict_tsya[word] = 1\n",
    "                    else:\n",
    "                        dict_tsya[word] += 1\n",
    "                if n_search.search(word) is not None or nn_search.search(word) is not None:\n",
    "                    if word not in dict_nn:\n",
    "                        dict_nn[word] = 1\n",
    "                    else:\n",
    "                        dict_nn[word] += 1\n",
    "\n",
    "            line = f.readline()\n",
    "            stripped_line = line.strip()\n",
    "            line_words = stripped_line.split()\n",
    "    k = 0\n",
    "    for i,word in enumerate(dict_tsya):\n",
    "        if 'тся' in word:\n",
    "            if word.replace('тся', 'ться') in dict_tsya:\n",
    "                tsya_data.loc[k] = [word, dict_tsya[word], word.replace('тся', 'ться'), dict_tsya[word.replace('тся', 'ться')]]\n",
    "                k+=1\n",
    "            else:\n",
    "                tsya_data.loc[k] = [word, dict_tsya[word], word.replace('тся', 'ться'), 0]\n",
    "                k+=1\n",
    "        elif 'ться' in word and word.replace('ться', 'тся') not in dict_tsya:\n",
    "            tsya_data.loc[k] = [word.replace('ться', 'тся'), 0, word, dict_tsya[word]]\n",
    "            k+=1\n",
    "    k = 0\n",
    "    for i,word in enumerate(dict_nn):\n",
    "        if n_search.search(word) is not None:\n",
    "            word_pair = pattern_n.sub('нн', word)\n",
    "            if word_pair in dict_nn:\n",
    "                nn_data.loc[k] = [word, dict_nn[word], word_pair, dict_nn[word_pair]]\n",
    "                k+=1\n",
    "            else:\n",
    "                nn_data.loc[k] = [word, dict_nn[word], word_pair, 0]\n",
    "                k+=1\n",
    "        elif nn_search.search(word) is not None and pattern_nn.sub('н', word) not in dict_nn:\n",
    "            nn_data.loc[k] = [pattern_nn.sub('н', word), 0, word, dict_nn[word]]\n",
    "            k+=1\n",
    "    nn_data.to_csv(outputfile_nn, index=False)\n",
    "    tsya_data.to_csv(outputfile_tsya, index=False)\n",
    "\n",
    "    return tsya_data, nn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsya_data, nn_data = get_statistics(\"datasets/dataset_hardsoft_correct.txt\", \n",
    "                                    \"statistics_tsya_magazines.csv\", \n",
    "                                    \"statistics_nn_magazines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsya_data_news, nn_data_news = get_statistics(\"datasets/news_dataset_hardsoft_correct.txt\", \n",
    "                                    \"statistics_tsya_news.csv\", \n",
    "                                    \"statistics_nn_news.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get statistics of pleminary texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristina/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "dict_tsya = {}\n",
    "dict_nn = {}\n",
    "tsya_data = pd.DataFrame(columns=['word', 'value_count', 'pair_word', 'value_cout_pair'])\n",
    "nn_data = pd.DataFrame(columns=['word', 'value_count', 'pair_word', 'value_cout_pair'])\n",
    "\n",
    "nn_search = re.compile(r'\\wнн([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|'\n",
    "                               r'ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b',\n",
    "                               re.IGNORECASE)  # the words, which contain \"н\" in the middle or in the end of word\n",
    "n_search = re.compile(r'[аоэеиыуёюя]н([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|'\n",
    "                              r'ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b',\n",
    "                              re.IGNORECASE)\n",
    "pattern_nn = re.compile(\n",
    "            r'(?-i:нн)'\n",
    "            r'(?=([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b)',\n",
    "            re.IGNORECASE)\n",
    "pattern_n = re.compile(\n",
    "            r'(?<=[аоэеиыуёюя])(?-i:н)'\n",
    "            r'(?=([аоыяеи]|ый|ого|ому|ом|ым|ая|ой|ую|ые|ыми|ых|ое|ою|ий|его|ему|ем|им|яя|ей|ею|юю|ие|ими|их|ее)\\b)',\n",
    "            re.IGNORECASE)\n",
    "data = pd.read_csv(\"datasets/prepared_data_hardsoft_correct.csv\", index_col=0)\n",
    "# tokenizer = BasicTokenizer(do_lower_case=False)\n",
    "data = data[~data.text.isnull()]\n",
    "for sentence in data.text.to_numpy():\n",
    "    word_list = tokenizer.tokenize(sentence)\n",
    "    for word in word_list:\n",
    "        word = word.lower()\n",
    "        if re.search('(тся)|(ться)',word) is not None:\n",
    "            if word not in dict_tsya:\n",
    "                dict_tsya[word] = 1\n",
    "            else:\n",
    "                dict_tsya[word] += 1\n",
    "        if n_search.search(word) is not None or nn_search.search(word) is not None:\n",
    "            if word not in dict_nn:\n",
    "                dict_nn[word] = 1\n",
    "            else:\n",
    "                dict_nn[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for i,word in tqdm(enumerate(dict_tsya)):\n",
    "    if 'тся' in word:\n",
    "        if word.replace('тся', 'ться') in dict_tsya:\n",
    "            tsya_data.loc[k] = [word, dict_tsya[word], word.replace('тся', 'ться'), dict_tsya[word.replace('тся', 'ться')]]\n",
    "            k+=1\n",
    "        else:\n",
    "            tsya_data.loc[k] = [word, dict_tsya[word], word.replace('тся', 'ться'), 0]\n",
    "            k+=1\n",
    "    elif 'ться' in word and word.replace('ться', 'тся') not in dict_tsya:\n",
    "        tsya_data.loc[k] = [word.replace('ться', 'тся'), 0, word, dict_tsya[word]]\n",
    "        k+=1\n",
    "k = 0\n",
    "for i,word in tqdm(enumerate(dict_nn)):\n",
    "    if n_search.search(word) is not None:\n",
    "        word_pair = pattern_n.sub('нн', word)\n",
    "        if word_pair in dict_nn:\n",
    "            nn_data.loc[k] = [word, dict_nn[word], word_pair, dict_nn[word_pair]]\n",
    "            k+=1\n",
    "        else:\n",
    "            nn_data.loc[k] = [word, dict_nn[word], word_pair, 0]\n",
    "            k+=1\n",
    "    elif nn_search.search(word) is not None and pattern_nn.sub('н', word) not in dict_nn:\n",
    "        nn_data.loc[k] = [pattern_nn.sub('н', word), 0, word, dict_nn[word]]\n",
    "        k+=1\n",
    "nn_data.to_csv(\"statistics_nn_magazines_pleminary_data.csv\", index=False)\n",
    "tsya_data.to_csv(\"statistics_tsya_magazines_pleminary_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magazines. tsya + nn, corrected schitanniy sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionaries...\n",
      "CPU times: user 77.8 ms, sys: 32.8 ms, total: 111 ms\n",
      "Wall time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generator = SyntheticDatasetGenerator(all_data='all_data.txt', output_file = 'data/dataset.txt', generate_type=['tsya', 'nn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristina/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16135507 entries, 0 to 16135506\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   text    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.7 GB\n",
      "None\n",
      "Add schitannye\n",
      "-1369\n",
      "Data size: 16136916\n",
      "Marking tsya/tysya sentences...\n",
      "1307057 593942\n",
      "Data size: 16136916\n",
      "Marking n/nn sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristina/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4599270 2599493\n",
      "Data size: 16136916\n",
      "Generating error tsya ...\n",
      "Data size: 16136916\n",
      "Generating error tysya ...\n",
      "Data size: 16136916\n",
      "Generating error n ...\n",
      "Data size: 16136916\n",
      "Generating error nn ...\n",
      "Data size: 16136916\n",
      "Filtering out the sentences that cannot be errorified...\n",
      "Output sentences: 1097533\n",
      "Data size: 1097533\n",
      "Errorifying sentences...\n",
      "['text', 'tsya_words_errorified', 'tysya_words_errorified', 'n_words_errorified', 'nn_words_errorified', 'tsya_words', 'tysya_words', 'n_words', 'nn_words']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text  \\\n",
      "0        В недавней вашей прозе о Слуцком* вы так описываете его поэтику: 'хриплое клокотание'; 'страшная и обыденная жизнь и смерть, страшно обыденная и обыденно страшная'; 'разговорная речь с вкрапленьями профессионального и бытового жаргона'; 'небрежный (как бы) или иронический тон высказывания и тут же рядом — речь ораторская, поддержанная высокой архаикой вплоть до церковнославянизмов'; 'речевой сплав горнего и дольнего' — и далее, как бы итожа: 'преткновенная гармония', 'лиро-эпос'...   \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                           Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                          О. Ч. К любым языковым формулам надо относиться осторожно, хотя и сказано энергично.   \n",
      "3                                                                                                                                                                                                                                                                                                                                                                         Для кого-то так относиться к замыслу важно — тому же Бродскому, который писал достаточно протяженные, синтаксически развернутые вещи.   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Картина хороша, но это жанр.   \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ...   \n",
      "1097528                                                                                                                                                                                                                                                                                                                                                                                                                                                 считаные денежки-то…) был ремонт институтских туалетов.   \n",
      "1097529                                                                                                                                                                                                                                                                                                                                                                                                                                                    Жар там был сухой, и одежда сохла в считаные минуты.   \n",
      "1097530                                                                                                                                                                                                                                                                                                                                                                                              В Москве, где считаные люди помнили, в какой день празднуется Рождество, большинство в глаза не видели Св.   \n",
      "1097531                                                                                                                                                                                                                                                                                 Пияшева даже успела начать это дело, в считаные дни собрала 10 тысяч заявок на приватизацию, но Верховный Совет принял закон, который предусматривал другую схему — ту самую, которая дала простор для 'прихватизации'.   \n",
      "1097532                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Освобождены считаные единицы.   \n",
      "\n",
      "        tsya_words_errorified tysya_words_errorified n_words_errorified  \\\n",
      "0                         NaN                    NaN         [жаргонна]   \n",
      "1                         NaN                    NaN                NaN   \n",
      "2                         NaN            [относится]                NaN   \n",
      "3                         NaN            [относится]                NaN   \n",
      "4                         NaN                    NaN         [Картинна]   \n",
      "...                       ...                    ...                ...   \n",
      "1097528                   NaN                    NaN        [считанные]   \n",
      "1097529                   NaN                    NaN        [считанные]   \n",
      "1097530                   NaN                    NaN        [считанные]   \n",
      "1097531                   NaN                    NaN        [считанные]   \n",
      "1097532                   NaN                    NaN        [считанные]   \n",
      "\n",
      "        nn_words_errorified tsya_words   tysya_words     n_words  \\\n",
      "0                       NaN        NaN           NaN   [жаргона]   \n",
      "1               [осмыслено]        NaN           NaN         NaN   \n",
      "2                       NaN        NaN  [относиться]         NaN   \n",
      "3                       NaN        NaN  [относиться]         NaN   \n",
      "4                       NaN        NaN           NaN   [Картина]   \n",
      "...                     ...        ...           ...         ...   \n",
      "1097528                 NaN        NaN           NaN  [считаные]   \n",
      "1097529                 NaN        NaN           NaN  [считаные]   \n",
      "1097530                 NaN        NaN           NaN  [считаные]   \n",
      "1097531                 NaN        NaN           NaN  [считаные]   \n",
      "1097532                 NaN        NaN           NaN  [считаные]   \n",
      "\n",
      "             nn_words  \\\n",
      "0                 NaN   \n",
      "1        [осмысленно]   \n",
      "2                 NaN   \n",
      "3                 NaN   \n",
      "4                 NaN   \n",
      "...               ...   \n",
      "1097528           NaN   \n",
      "1097529           NaN   \n",
      "1097530           NaN   \n",
      "1097531           NaN   \n",
      "1097532           NaN   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          error  \\\n",
      "0        В недавней вашей прозе о Слуцком* вы так описываете его поэтику: 'хриплое клокотание'; 'страшная и обыденная жизнь и смерть, страшно обыденная и обыденно страшная'; 'разговорная речь с вкрапленьями профессионального и бытового жаргона'; 'небрежный (как бы) или иронический тон высказывания и тут же рядом — речь ораторская, поддержанная высокой архаикой вплоть до церковнославянизмов'; 'речевой сплав горнего и дольнего' — и далее, как бы итожа: 'преткновенная гармония', 'лиро-эпос'...   \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                           Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                          О. Ч. К любым языковым формулам надо относиться осторожно, хотя и сказано энергично.   \n",
      "3                                                                                                                                                                                                                                                                                                                                                                         Для кого-то так относиться к замыслу важно — тому же Бродскому, который писал достаточно протяженные, синтаксически развернутые вещи.   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Картина хороша, но это жанр.   \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ...   \n",
      "1097528                                                                                                                                                                                                                                                                                                                                                                                                                                                 считаные денежки-то…) был ремонт институтских туалетов.   \n",
      "1097529                                                                                                                                                                                                                                                                                                                                                                                                                                                    Жар там был сухой, и одежда сохла в считаные минуты.   \n",
      "1097530                                                                                                                                                                                                                                                                                                                                                                                              В Москве, где считаные люди помнили, в какой день празднуется Рождество, большинство в глаза не видели Св.   \n",
      "1097531                                                                                                                                                                                                                                                                                 Пияшева даже успела начать это дело, в считаные дни собрала 10 тысяч заявок на приватизацию, но Верховный Совет принял закон, который предусматривал другую схему — ту самую, которая дала простор для 'прихватизации'.   \n",
      "1097532                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Освобождены считаные единицы.   \n",
      "\n",
      "        error_type  error_word  \n",
      "0             none         NaN  \n",
      "1             none         NaN  \n",
      "2             none         NaN  \n",
      "3             none         NaN  \n",
      "4             none         NaN  \n",
      "...            ...         ...  \n",
      "1097528       none         NaN  \n",
      "1097529       none         NaN  \n",
      "1097530       none         NaN  \n",
      "1097531       none         NaN  \n",
      "1097532       none         NaN  \n",
      "\n",
      "[1097533 rows x 12 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097533it [13:07, 1393.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'tsya_words_errorified', 'tysya_words_errorified',\n",
      "       'n_words_errorified', 'nn_words_errorified', 'tsya_words',\n",
      "       'tysya_words', 'n_words', 'nn_words', 'error', 'error_type',\n",
      "       'error_word'],\n",
      "      dtype='object')\n",
      "Data size: 2195066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17477/2195066 [00:02<05:43, 6337.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16417 'становиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 38164/2195066 [00:05<05:56, 6056.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37368 'держатся' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 46111/2195066 [00:07<07:24, 4835.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45228 'проснутся' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 124970/2195066 [00:18<04:32, 7591.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123476 'прокормится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 146828/2195066 [00:20<04:49, 7068.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146032 'встретится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 168571/2195066 [00:24<04:55, 6866.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167813 'приесться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 272178/2195066 [00:37<04:30, 7099.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271250 'относиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 277986/2195066 [00:38<04:41, 6818.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277166 'возвратится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 290525/2195066 [00:40<04:47, 6628.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289205 'выдвинутся' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 295711/2195066 [00:41<05:59, 5280.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295159 'опомнится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 298749/2195066 [00:41<06:32, 4826.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298243 'прикоснутся' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 300779/2195066 [00:42<06:27, 4887.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299752 'становиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 304680/2195066 [00:43<06:43, 4684.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303717 'находиться' is not in list\n",
      "304091 'находиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 324129/2195066 [00:47<06:15, 4977.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323110 'корениться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 328720/2195066 [00:48<06:27, 4810.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328135 'готовиться' is not in list\n",
      "328533 'множиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 333346/2195066 [00:48<06:01, 5148.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332649 'исполнятся' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 334926/2195066 [00:49<06:09, 5028.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334170 'углубится' is not in list\n",
      "334506 'избавится' is not in list\n",
      "334679 'водиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 339395/2195066 [00:50<06:30, 4748.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338450 'женится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 340835/2195066 [00:50<06:35, 4685.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340120 'беспокоится' is not in list\n",
      "340935 'воспроизводится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 342385/2195066 [00:50<06:08, 5030.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341676 'женится' is not in list\n",
      "342042 'держаться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 344394/2195066 [00:51<06:17, 4902.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343508 'отмахнутся' is not in list\n",
      "344397 'извинятся' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 345955/2195066 [00:51<06:13, 4953.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345001 'избавится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 349446/2195066 [00:52<06:32, 4698.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348465 'завершится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 352948/2195066 [00:53<12:30, 2454.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352068 'заразиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 354415/2195066 [00:54<08:23, 3656.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353831 'воспроизводиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 355833/2195066 [00:54<07:16, 4212.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354986 'стремится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 357905/2195066 [00:54<06:28, 4725.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356932 'подчинится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 368046/2195066 [00:56<05:32, 5492.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366908 'теплиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 369525/2195066 [00:57<04:47, 6340.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368558 'учиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 394880/2195066 [01:00<04:05, 7335.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394140 'разрушится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 430060/2195066 [01:05<04:18, 6836.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428634 'родится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 455011/2195066 [01:09<03:12, 9042.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453395 'вернутся' is not in list\n",
      "454082 'грезиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 464884/2195066 [01:11<04:58, 5799.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464004 'стремиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 473776/2195066 [01:12<04:10, 6861.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472385 'поделится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 500935/2195066 [01:16<05:26, 5192.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500184 'находиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 503561/2195066 [01:16<05:24, 5216.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502996 'становиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 513934/2195066 [01:19<05:44, 4884.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513012 'проявится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 517007/2195066 [01:19<05:26, 5144.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516208 'стремиться' is not in list\n",
      "517139 'обходиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 519092/2195066 [01:20<05:24, 5167.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518446 'готовиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 523337/2195066 [01:20<05:30, 5064.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522530 'становиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 524860/2195066 [01:21<05:36, 4965.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524074 'приходиться' is not in list\n",
      "524098 'сохранится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 551328/2195066 [01:25<04:53, 5607.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550933 'переселится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 617174/2195066 [01:35<03:43, 7046.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616036 'стремиться' is not in list\n",
      "616529 'сговорится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 627681/2195066 [01:36<03:26, 7579.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626260 'манны' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 696047/2195066 [01:48<03:15, 7676.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694817 'отряхнутся' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 767631/2195066 [01:59<02:43, 8715.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766671 'манны' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 821773/2195066 [02:06<03:45, 6097.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820516 'вериться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 828258/2195066 [02:08<04:01, 5651.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "827288 'окончиться' is not in list\n",
      "827289 'окончиться' is not in list\n",
      "828295 'струиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 843536/2195066 [02:11<04:00, 5618.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842882 'подлине' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 857707/2195066 [02:13<03:15, 6848.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "856954 'уладиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 862052/2195066 [02:13<03:09, 7021.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860833 'понравиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 872669/2195066 [02:15<03:23, 6487.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871886 'распорядится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 932457/2195066 [02:24<03:03, 6863.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931150 'строиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 962821/2195066 [02:28<03:06, 6623.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961748 'присоединится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 974521/2195066 [02:30<02:48, 7261.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973548 'примирится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1035751/2195066 [02:39<02:45, 7005.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034291 'клеиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1078284/2195066 [02:45<02:42, 6861.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077281 'избавится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1097716/2195066 [02:48<02:54, 6287.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096566 'возвратится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2195066/2195066 [05:36<00:00, 6525.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 2195066\n",
      "CPU times: user 25min 13s, sys: 18.8 s, total: 25min 32s\n",
      "Wall time: 25min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generated_data, tokens, labels = generator.generate(to_file='datasets/dataset_hardsoft_correct_doubled_sentences.txt', prepared_path='datasets/prepared_data_hardsoft_correct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsya_data, nn_data = get_statistics(\"datasets/dataset_hardsoft_correct2.txt\", \n",
    "                                    \"statistics_tsya_magazines2.csv\", \n",
    "                                    \"statistics_nn_magazines2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>error</th>\n",
       "      <th>error_word</th>\n",
       "      <th>error_type</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.</td>\n",
       "      <td>Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмыслено.</td>\n",
       "      <td>осмыслено</td>\n",
       "      <td>nn</td>\n",
       "      <td>REPLACE_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097534</th>\n",
       "      <td>Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.</td>\n",
       "      <td>Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>REPLACE_none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                        text  \\\n",
       "1        Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.   \n",
       "1097534  Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.   \n",
       "\n",
       "                                                                                                                       error  \\\n",
       "1         Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмыслено.   \n",
       "1097534  Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.   \n",
       "\n",
       "        error_word error_type           tag  \n",
       "1        осмыслено         nn    REPLACE_nn  \n",
       "1097534        NaN       none  REPLACE_none  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data[generated_data['text'] == \"Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none     548151\n",
      "n        221721\n",
      "tysya    122326\n",
      "tsya     118893\n",
      "nn        85033\n",
      "Name: error_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(generated_data['error_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magazines dataset. Only tsya/tysya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionaries...\n",
      "CPU times: user 6.54 ms, sys: 0 ns, total: 6.54 ms\n",
      "Wall time: 5.71 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generator = SyntheticDatasetGenerator(all_data='all_data.txt', output_file = 'data/dataset.txt', generate_type=['tsya'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristina/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16135506 entries, 0 to 16135505\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   text    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.7 GB\n",
      "None\n",
      "Marking tsya/tysya sentences...\n",
      "1306636 593751\n",
      "Data size: 16135506\n",
      "Generating error tsya ...\n",
      "Data size: 16135506\n",
      "Generating error tysya ...\n",
      "Data size: 16135506\n",
      "Filtering out the sentences that cannot be errorified...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sentences: 498256\n",
      "Data size: 498256\n",
      "Errorifying sentences...\n",
      "['text', 'tsya_words_errorified', 'tysya_words_errorified', 'tsya_words', 'tysya_words']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "498256it [05:37, 1475.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 498256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 498256/498256 [01:26<00:00, 5772.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 498256\n",
      "CPU times: user 9min 40s, sys: 7.95 s, total: 9min 48s\n",
      "Wall time: 9min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generated_data, tokens, labels = generator.generate(to_file='datasets/dataset_only_tsya.txt', prepared_path='datasets/prepared_data_only_tsya.csv')\n",
    "# Input sentences should be 15664256 before sentence_tokenize function: correct\n",
    "# Input sentences should be 16135506: correct\n",
    "# Output sentences should be 1057067: correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498256, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News dataset. tsya + nn, corrected schitanniy sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionaries...\n",
      "CPU times: user 114 ms, sys: 4.04 ms, total: 118 ms\n",
      "Wall time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generator = SyntheticDatasetGenerator(all_data='all_news_dataset.txt', output_file = 'data/news_dataset.txt', generate_type=['tsya', 'nn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristina/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3990976 entries, 0 to 3990975\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   text    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.2 GB\n",
      "None\n",
      "Add schitannye\n",
      "-384\n",
      "Data size: 3991362\n",
      "Marking tsya/tysya sentences...\n",
      "514831 167124\n",
      "Data size: 3991362\n",
      "Marking n/nn sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristina/IndustrialImmersion/venv_kris/lib/python3.7/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1742209 911734\n",
      "Data size: 3991362\n",
      "Generating error tsya ...\n",
      "Data size: 3991362\n",
      "Generating error tysya ...\n",
      "Data size: 3991362\n",
      "Generating error n ...\n",
      "Data size: 3991362\n",
      "Generating error nn ...\n",
      "Data size: 3991362\n",
      "Filtering out the sentences that cannot be errorified...\n",
      "Output sentences: 473034\n",
      "Data size: 473034\n",
      "Errorifying sentences...\n",
      "['text', 'tsya_words_errorified', 'tysya_words_errorified', 'n_words_errorified', 'nn_words_errorified', 'tsya_words', 'tysya_words', 'n_words', 'nn_words']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                 text  \\\n",
      "0                За час до начала концерта свою работу открыли творческие мастерские, где дети могли научиться изготавливать рождественские подарки и сувениры – рисовать ангелов, расписывать рождественские пряники, елочные шары, делать открытки.   \n",
      "1                                                                                                                        Было организовано бесплатное рождественское кафе, сладости и пироги для которого предоставили известные кондитерские города.   \n",
      "2                                                                                                                                                                                                      Каждому хотелось поделиться теплом своей души.   \n",
      "3                                                                                                                                                                                                     Возбуждено дело по 162-й статье УК РФ (разбой).   \n",
      "4                                                                                                                                                                                                Ранее дядю Ким Чен Ына называли вторым лицом в КНДР.   \n",
      "...                                                                                                                                                                                                                                               ...   \n",
      "473029  В считаные минуты одна и та же комната превращалась то в зал венецианского палаццо эпохи Возрождения, то в японскую чайную комнату XVI века, то в подводное царство — для дискотеки в стиле 70-80-х годов под названием 'В гостях у Нептуна'.   \n",
      "473030                                                                                                                                      Те же, кто предполагал, что примет участие в конкурсе, 'отсеялись' за считаные дни до вскрытия конвертов.   \n",
      "473031                                                                 Читатель \"Фонтанки\", ходивший в море на рыболовецком судне, стал свидетелем того, как подлодка Северного флота едва не протаранила корабль, пройдя в считаных метрах от борта.   \n",
      "473032                                                                                                         И если в больших городах спасатели могут прибыть на место ДТП в считаные минуты, то федеральные трассы удалены от пунктов таких служб.   \n",
      "473033                                                                                                                                          Но это впечатление обманчиво: чаще всего 34-й номер \"Зенита\" выходил на поле лишь на считаные минуты.   \n",
      "\n",
      "       tsya_words_errorified tysya_words_errorified n_words_errorified  \\\n",
      "0                        NaN             [научится]                NaN   \n",
      "1                        NaN                    NaN    [организованно]   \n",
      "2                        NaN            [поделится]                NaN   \n",
      "3                        NaN                    NaN      [Возбужденно]   \n",
      "4                        NaN                    NaN           [Раннее]   \n",
      "...                      ...                    ...                ...   \n",
      "473029                   NaN                    NaN        [считанные]   \n",
      "473030                   NaN                    NaN        [считанные]   \n",
      "473031                   NaN                    NaN        [считанных]   \n",
      "473032                   NaN                    NaN        [считанные]   \n",
      "473033                   NaN                    NaN        [считанные]   \n",
      "\n",
      "       nn_words_errorified tsya_words   tysya_words         n_words nn_words  \\\n",
      "0                      NaN        NaN   [научиться]             NaN      NaN   \n",
      "1                      NaN        NaN           NaN  [организовано]      NaN   \n",
      "2                      NaN        NaN  [поделиться]             NaN      NaN   \n",
      "3                      NaN        NaN           NaN    [Возбуждено]      NaN   \n",
      "4                      NaN        NaN           NaN         [Ранее]      NaN   \n",
      "...                    ...        ...           ...             ...      ...   \n",
      "473029                 NaN        NaN           NaN      [считаные]      NaN   \n",
      "473030                 NaN        NaN           NaN      [считаные]      NaN   \n",
      "473031                 NaN        NaN           NaN      [считаных]      NaN   \n",
      "473032                 NaN        NaN           NaN      [считаные]      NaN   \n",
      "473033                 NaN        NaN           NaN      [считаные]      NaN   \n",
      "\n",
      "                                                                                                                                                                                                                                                error  \\\n",
      "0                За час до начала концерта свою работу открыли творческие мастерские, где дети могли научиться изготавливать рождественские подарки и сувениры – рисовать ангелов, расписывать рождественские пряники, елочные шары, делать открытки.   \n",
      "1                                                                                                                        Было организовано бесплатное рождественское кафе, сладости и пироги для которого предоставили известные кондитерские города.   \n",
      "2                                                                                                                                                                                                      Каждому хотелось поделиться теплом своей души.   \n",
      "3                                                                                                                                                                                                     Возбуждено дело по 162-й статье УК РФ (разбой).   \n",
      "4                                                                                                                                                                                                Ранее дядю Ким Чен Ына называли вторым лицом в КНДР.   \n",
      "...                                                                                                                                                                                                                                               ...   \n",
      "473029  В считаные минуты одна и та же комната превращалась то в зал венецианского палаццо эпохи Возрождения, то в японскую чайную комнату XVI века, то в подводное царство — для дискотеки в стиле 70-80-х годов под названием 'В гостях у Нептуна'.   \n",
      "473030                                                                                                                                      Те же, кто предполагал, что примет участие в конкурсе, 'отсеялись' за считаные дни до вскрытия конвертов.   \n",
      "473031                                                                 Читатель \"Фонтанки\", ходивший в море на рыболовецком судне, стал свидетелем того, как подлодка Северного флота едва не протаранила корабль, пройдя в считаных метрах от борта.   \n",
      "473032                                                                                                         И если в больших городах спасатели могут прибыть на место ДТП в считаные минуты, то федеральные трассы удалены от пунктов таких служб.   \n",
      "473033                                                                                                                                          Но это впечатление обманчиво: чаще всего 34-й номер \"Зенита\" выходил на поле лишь на считаные минуты.   \n",
      "\n",
      "       error_type  error_word  \n",
      "0            none         NaN  \n",
      "1            none         NaN  \n",
      "2            none         NaN  \n",
      "3            none         NaN  \n",
      "4            none         NaN  \n",
      "...           ...         ...  \n",
      "473029       none         NaN  \n",
      "473030       none         NaN  \n",
      "473031       none         NaN  \n",
      "473032       none         NaN  \n",
      "473033       none         NaN  \n",
      "\n",
      "[473034 rows x 12 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "473034it [05:24, 1459.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'tsya_words_errorified', 'tysya_words_errorified',\n",
      "       'n_words_errorified', 'nn_words_errorified', 'tsya_words',\n",
      "       'tysya_words', 'n_words', 'nn_words', 'error', 'error_type',\n",
      "       'error_word'],\n",
      "      dtype='object')\n",
      "Data size: 946068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13059/946068 [00:01<02:14, 6933.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11712 'заключены' is not in list\n",
      "12482 'моченый' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 14443/946068 [00:02<02:15, 6882.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13717 'направленно' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20020/946068 [00:02<02:12, 6966.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18999 'сосредоточится' is not in list\n",
      "19175 'наладиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 36671/946068 [00:05<02:13, 6812.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35501 'расшириться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 108364/946068 [00:15<02:04, 6755.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107102 'ценны' is not in list\n",
      "107105 'ценны' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 118636/946068 [00:17<02:00, 6844.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117588 'объединится' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 126192/946068 [00:18<02:05, 6544.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124933 'бракованы' is not in list\n",
      "124934 'возбужденно' is not in list\n",
      "124935 'электроны' is not in list\n",
      "126296 'бракованы' is not in list\n",
      "126297 'возбужденно' is not in list\n",
      "126298 'электроны' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 132778/946068 [00:19<02:06, 6452.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131761 'Законно' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 139453/946068 [00:20<02:01, 6648.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138767 'говориться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 163017/946068 [00:23<01:53, 6919.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161877 'запрещены' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 168663/946068 [00:24<01:50, 7066.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167487 'законном' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 243986/946068 [00:35<01:38, 7143.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242533 'финна' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 267116/946068 [00:38<01:41, 6660.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265853 'пригодиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 319767/946068 [00:47<01:28, 7107.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318660 'времена' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 357515/946068 [00:52<01:29, 6593.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356521 'анны' is not in list\n",
      "356522 'причинены' is not in list\n",
      "356523 'надумано' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 398997/946068 [00:58<01:20, 6755.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398121 'разрушатся' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 408773/946068 [01:00<01:18, 6881.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407936 'бояться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 428514/946068 [01:02<01:19, 6523.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427519 'вооружиться' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 472806/946068 [01:09<01:06, 7120.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472038 'вооружатся' is not in list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 946068/946068 [02:22<00:00, 6657.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 946068\n",
      "CPU times: user 10min 12s, sys: 5.98 s, total: 10min 17s\n",
      "Wall time: 10min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generated_data_news, tokens, labels = generator.generate(to_file='datasets/news_dataset_hardsoft_correct_doubled_sentences.txt', prepared_path='datasets/news_prepared_data_hardsoft_correct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(472628, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old\n",
    "generated_data_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(472636, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none     236567\n",
      "n        138534\n",
      "tsya      53379\n",
      "tysya     32163\n",
      "nn        11993\n",
      "Name: error_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(generated_data_news['error_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsya_data_news, nn_data_news = get_statistics(\"datasets/news_dataset_hardsoft_correct2.txt\", \n",
    "                                    \"statistics_tsya_news2.csv\", \n",
    "                                    \"statistics_nn_news2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>value_count</th>\n",
       "      <th>pair_word</th>\n",
       "      <th>value_cout_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>организовано</td>\n",
       "      <td>522</td>\n",
       "      <td>организованно</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>возбуждено</td>\n",
       "      <td>9178</td>\n",
       "      <td>возбужденно</td>\n",
       "      <td>8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ына</td>\n",
       "      <td>49</td>\n",
       "      <td>ынна</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>районе</td>\n",
       "      <td>4097</td>\n",
       "      <td>районне</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>направлена</td>\n",
       "      <td>644</td>\n",
       "      <td>направленна</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27819</th>\n",
       "      <td>нетленой</td>\n",
       "      <td>0</td>\n",
       "      <td>нетленной</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27820</th>\n",
       "      <td>ромалдана</td>\n",
       "      <td>1</td>\n",
       "      <td>ромалданна</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27821</th>\n",
       "      <td>монотоная</td>\n",
       "      <td>0</td>\n",
       "      <td>монотонная</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27822</th>\n",
       "      <td>тилькина</td>\n",
       "      <td>1</td>\n",
       "      <td>тилькинна</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27823</th>\n",
       "      <td>современей</td>\n",
       "      <td>0</td>\n",
       "      <td>современней</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27824 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word value_count      pair_word value_cout_pair\n",
       "0      организовано         522  организованно             546\n",
       "1        возбуждено        9178    возбужденно            8602\n",
       "2               ына          49           ынна               0\n",
       "3            районе        4097        районне               0\n",
       "4        направлена         644    направленна             599\n",
       "...             ...         ...            ...             ...\n",
       "27819      нетленой           0      нетленной               1\n",
       "27820     ромалдана           1     ромалданна               0\n",
       "27821     монотоная           0     монотонная               1\n",
       "27822      тилькина           1      тилькинна               0\n",
       "27823    современей           0    современней               1\n",
       "\n",
       "[27824 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_data_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download News dataset and save to one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# archive_url = 'http://bit.ly/2pvhWZm'\n",
    "# filename = wget.download(archive_url, os.path.join('./data', 'news' + '.zip'))\n",
    "# pyunpack.Archive('./data/news.zip').extractall('./data')\n",
    "\n",
    "# file_list_full = []\n",
    "# for folder in ['Fontanka', 'Lenta', 'KP', 'Interfax']:\n",
    "#     file_list_year = []\n",
    "#     for year_folder in os.listdir('./news/' + folder + '/texts/'):\n",
    "#         file_list = sorted(glob.glob(os.path.join('./news/'+folder + '/texts/' + year_folder + '/', '*.txt')))\n",
    "#         file_list_year.append(file_list)\n",
    "#     file_list_full.append(file_list_year)\n",
    "    \n",
    "# with open('./data/all_news_dataset.txt', 'w') as file:\n",
    "#     for file_list_year in file_list_full:\n",
    "#         for file_list in file_list_year:\n",
    "#             input_lines = fileinput.input(file_list)\n",
    "#             file.writelines(input_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = pd.read_csv('./data/Fontanka/metatable_2017.csv', sep='\\t', encoding='utf8')\n",
    "# os.listdir('news/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24959948471290627"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(generated_data['error_type'] == 'none').sum() / len(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25006982235500225"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(generated_data_news['error_type'] == 'none').sum() / len(generated_data_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>error</th>\n",
       "      <th>error_word</th>\n",
       "      <th>error_type</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В недавней вашей прозе о Слуцком* вы так описываете его поэтику: 'хриплое клокотание'; 'страшная и обыденная жизнь и смерть, страшно обыденная и обыденно страшная'; 'разговорная речь с вкрапленьями профессионального и бытового жаргона'; 'небрежный (как бы) или иронический тон высказывания и тут же рядом — речь ораторская, поддержанная высокой архаикой вплоть до церковнославянизмов'; 'речевой сплав горнего и дольнего' — и далее, как бы итожа: 'преткновенная гармония', 'лиро-эпос'...</td>\n",
       "      <td>В недавней вашей прозе о Слуцком* вы так описываете его поэтику: 'хриплое клокотание'; 'страшная и обыденная жизнь и смерть, страшно обыденная и обыденно страшная'; 'разговорная речь с вкрапленьями профессионального и бытового жаргонна'; 'небрежный (как бы) или иронический тон высказывания и тут же рядом — речь ораторская, поддержанная высокой архаикой вплоть до церковнославянизмов'; 'речевой сплав горнего и дольнего' — и далее, как бы итожа: 'преткновенная гармония', 'лиро-эпос'...</td>\n",
       "      <td>жаргонна</td>\n",
       "      <td>n</td>\n",
       "      <td>REPLACE_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.</td>\n",
       "      <td>Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>REPLACE_none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>О. Ч. К любым языковым формулам надо относиться осторожно, хотя и сказано энергично.</td>\n",
       "      <td>О. Ч. К любым языковым формулам надо относится осторожно, хотя и сказано энергично.</td>\n",
       "      <td>относится</td>\n",
       "      <td>tysya</td>\n",
       "      <td>REPLACE_tysya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Для кого-то так относиться к замыслу важно — тому же Бродскому, который писал достаточно протяженные, синтаксически развернутые вещи.</td>\n",
       "      <td>Для кого-то так относится к замыслу важно — тому же Бродскому, который писал достаточно протяженные, синтаксически развернутые вещи.</td>\n",
       "      <td>относится</td>\n",
       "      <td>tysya</td>\n",
       "      <td>REPLACE_tysya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Картина хороша, но это жанр.</td>\n",
       "      <td>Картинна хороша, но это жанр.</td>\n",
       "      <td>Картинна</td>\n",
       "      <td>n</td>\n",
       "      <td>REPLACE_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096085</th>\n",
       "      <td>Душно в комнате было, и на стене картина, как форточка, открывалась,</td>\n",
       "      <td>Душно в комнате было, и на стене картинна, как форточка, открывалась,</td>\n",
       "      <td>картинна</td>\n",
       "      <td>n</td>\n",
       "      <td>REPLACE_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096086</th>\n",
       "      <td>Посмотри – все дробится в его узоре, и на самой границе небес и вод обнажается детский затылок моря, закругляется горизонт.</td>\n",
       "      <td>Посмотри – все дробится в его узоре, и на самой границе небес и вод обнажается детский затылок моря, закругляется горизонт.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>REPLACE_none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096087</th>\n",
       "      <td>Иногда асфальт становится на дыбы, корни и грибы растут из него.</td>\n",
       "      <td>Иногда асфальт становиться на дыбы, корни и грибы растут из него.</td>\n",
       "      <td>становиться</td>\n",
       "      <td>tsya</td>\n",
       "      <td>REPLACE_tsya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096088</th>\n",
       "      <td>Вымерзают глубины до дна.</td>\n",
       "      <td>Вымерзают глубинны до дна.</td>\n",
       "      <td>глубинны</td>\n",
       "      <td>n</td>\n",
       "      <td>REPLACE_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096089</th>\n",
       "      <td>Обездвижены выси и воды, вымерзают глубины до дна.</td>\n",
       "      <td>Обездвижены выси и воды, вымерзают глубины до дна.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>REPLACE_none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096088 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text  \\\n",
       "0        В недавней вашей прозе о Слуцком* вы так описываете его поэтику: 'хриплое клокотание'; 'страшная и обыденная жизнь и смерть, страшно обыденная и обыденно страшная'; 'разговорная речь с вкрапленьями профессионального и бытового жаргона'; 'небрежный (как бы) или иронический тон высказывания и тут же рядом — речь ораторская, поддержанная высокой архаикой вплоть до церковнославянизмов'; 'речевой сплав горнего и дольнего' — и далее, как бы итожа: 'преткновенная гармония', 'лиро-эпос'...   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                           Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                          О. Ч. К любым языковым формулам надо относиться осторожно, хотя и сказано энергично.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                         Для кого-то так относиться к замыслу важно — тому же Бродскому, который писал достаточно протяженные, синтаксически развернутые вещи.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Картина хороша, но это жанр.   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ...   \n",
       "1096085                                                                                                                                                                                                                                                                                                                                                                                                                                    Душно в комнате было, и на стене картина, как форточка, открывалась,   \n",
       "1096086                                                                                                                                                                                                                                                                                                                                                                             Посмотри – все дробится в его узоре, и на самой границе небес и вод обнажается детский затылок моря, закругляется горизонт.   \n",
       "1096087                                                                                                                                                                                                                                                                                                                                                                                                                                        Иногда асфальт становится на дыбы, корни и грибы растут из него.   \n",
       "1096088                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Вымерзают глубины до дна.   \n",
       "1096089                                                                                                                                                                                                                                                                                                                                                                                                                                                      Обездвижены выси и воды, вымерзают глубины до дна.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           error  \\\n",
       "0        В недавней вашей прозе о Слуцком* вы так описываете его поэтику: 'хриплое клокотание'; 'страшная и обыденная жизнь и смерть, страшно обыденная и обыденно страшная'; 'разговорная речь с вкрапленьями профессионального и бытового жаргонна'; 'небрежный (как бы) или иронический тон высказывания и тут же рядом — речь ораторская, поддержанная высокой архаикой вплоть до церковнославянизмов'; 'речевой сплав горнего и дольнего' — и далее, как бы итожа: 'преткновенная гармония', 'лиро-эпос'...   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                            Когда Лермонтов написал 'Есть речи — значенье Темно иль ничтожно...' — он-то написал это не ничтожно, а осмысленно.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                            О. Ч. К любым языковым формулам надо относится осторожно, хотя и сказано энергично.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                           Для кого-то так относится к замыслу важно — тому же Бродскому, который писал достаточно протяженные, синтаксически развернутые вещи.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Картинна хороша, но это жанр.   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n",
       "1096085                                                                                                                                                                                                                                                                                                                                                                                                                                    Душно в комнате было, и на стене картинна, как форточка, открывалась,   \n",
       "1096086                                                                                                                                                                                                                                                                                                                                                                              Посмотри – все дробится в его узоре, и на самой границе небес и вод обнажается детский затылок моря, закругляется горизонт.   \n",
       "1096087                                                                                                                                                                                                                                                                                                                                                                                                                                        Иногда асфальт становиться на дыбы, корни и грибы растут из него.   \n",
       "1096088                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Вымерзают глубинны до дна.   \n",
       "1096089                                                                                                                                                                                                                                                                                                                                                                                                                                                       Обездвижены выси и воды, вымерзают глубины до дна.   \n",
       "\n",
       "          error_word error_type            tag  \n",
       "0           жаргонна          n      REPLACE_n  \n",
       "1                NaN       none   REPLACE_none  \n",
       "2          относится      tysya  REPLACE_tysya  \n",
       "3          относится      tysya  REPLACE_tysya  \n",
       "4           Картинна          n      REPLACE_n  \n",
       "...              ...        ...            ...  \n",
       "1096085     картинна          n      REPLACE_n  \n",
       "1096086          NaN       none   REPLACE_none  \n",
       "1096087  становиться       tsya   REPLACE_tsya  \n",
       "1096088     глубинны          n      REPLACE_n  \n",
       "1096089          NaN       none   REPLACE_none  \n",
       "\n",
       "[1096088 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test_file in [\"test_nn/Gramota\", \"test_nn/Michail_collection\"]:\n",
    "#     with open(test_file + '.txt', 'r') as file:\n",
    "#         with open(test_file + '_doubled' + '.txt', 'w') as f:\n",
    "#             text = [line.strip() for line in file]\n",
    "#             for sentence in text:\n",
    "#                 sentence, _,sign = sentence.rpartition(',')\n",
    "#                 f.write(sentence + ',' + sign + '\\n')\n",
    "#                 if sign == \"+\":\n",
    "#                     f.write(sentence + ',' + '-' + '\\n')\n",
    "#                 else:\n",
    "#                     f.write(sentence + ',' + '+' + '\\n')\n",
    "# test_file = \"test_nn/Mozhno_itak_itak\"\n",
    "# with open(test_file + '.txt', 'r') as file:\n",
    "#     with open(test_file + '_doubled' + '.txt', 'w') as f:\n",
    "#         text = [line.strip() for line in file]\n",
    "#         for sentence in text:\n",
    "#             f.write(sentence + '\\n')\n",
    "#             f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ошибки, которые мы взяли в работу\n",
    "\n",
    "1. Заменить a на b:\n",
    "    - -ться <-> -тся: просто ищем тся **[РЕАЛИЗОВАНО]**\n",
    "    - н <-> нн (совершенно, длина): н/нн + список окончаний (см. ниже) **[РЕАЛИЗОВАНО]**\n",
    "    - течение <-> течении: просто ищем\n",
    "    - ни- <-> не-: не-ни в начале слова\n",
    "2. Вставить/убрать пробел: имеет ли смысл в рандомных местах? Наверное, не очень пока\n",
    "    - ни * <-> ни* (никто)\n",
    "    - то же <-> тоже\n",
    "    - что бы <-> чтобы (и чтоб)\n",
    "    - бестолку <-> бес толку\n",
    "    - (сложные слова) мега масштабы <-> мегамасштабы\n",
    "3. Вставить/убрать дефис:\n",
    "    - из-за <-> из за\n",
    "    - *-то <-> * то\n",
    "    - *-таки <-> * таки\n",
    "4. Комбинация (1) и (2):\n",
    "    - не кто <-> никто"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ошибки, которые мы пока не взяли в работу:\n",
    "1. Опечатки: вставить/заменить букву\n",
    "    - ве(ч)ером, в(а)ши, бес колебаний, белее того, без везти, ...\n",
    "2. Вставить предлог\n",
    "    - письмо (с) фотографиями, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging scheme\n",
    "\n",
    "#### Replace operations\n",
    "\n",
    "- replace_tsya\n",
    "- replace_tysya\n",
    "- replace_n\n",
    "- replace_nn\n",
    "- replace_techenii\n",
    "- replace_techenie\n",
    "- replace_ni\n",
    "- replace_ne\n",
    "\n",
    "#### Merge and Split operations\n",
    "\n",
    "- merge: ни кто -> никто\n",
    "- split: не весел -> невесел\n",
    "- merge_hyphen: из за -> из-за\n",
    "- split_hyphen: я-таки -> я таки\n",
    "- merge_replace_ni: не кто -> никто\n",
    "- merge_replace_ne:\n",
    "- split_replace_ni:\n",
    "- split_replace_ne: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Списки окончаний\n",
    "\n",
    "1. **Список окончаний прилагательных и причастий с н/нн**:  \n",
    "-ый, -ого, -ому, -ом, -ым, -ая, -ой, -ую, -ые, -ыми, -ых, -а, -о, -ы  \n",
    "На всякий случай мягкий вариант (лингвисты сказали не делать, но, может, всё-таки добавить на всякий случай?):  \n",
    "ий|его|ему|ем|им|яя|ей|юю|ие|ими|их|я|е|и  \n",
    "и пустое окончание, но нам оно не нужно, потому что там гласный вставляется: \"пустынен\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": ".venv_kris"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
